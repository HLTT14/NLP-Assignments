{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "963d1be30c2849e0922106c56e97df3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7be3ccb654404da4b7d8417dbc454d9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0c33796693b4b189133ecdd8b799310",
              "IPY_MODEL_880c43ac147a45a2afb92c56b3cc2efc"
            ]
          }
        },
        "7be3ccb654404da4b7d8417dbc454d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0c33796693b4b189133ecdd8b799310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f3a3e6c4e73455f9f8c198e2125cbe9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e953b6a1f4a14385ab60345fc9533c23"
          }
        },
        "880c43ac147a45a2afb92c56b3cc2efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a901bf460b6b430e950e00abf537d47b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440/440 [00:00&lt;00:00, 796B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d6cd2c81c174c92a357db59d84f0612"
          }
        },
        "4f3a3e6c4e73455f9f8c198e2125cbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e953b6a1f4a14385ab60345fc9533c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a901bf460b6b430e950e00abf537d47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d6cd2c81c174c92a357db59d84f0612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0b55d66f66048e98e9f3c8696939787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c1ad6290d50442488100632ba4c9c3eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68d32554cd11448989b40fb6acc6bdb2",
              "IPY_MODEL_8a80e8cb6c014590bfaff809e37219f6"
            ]
          }
        },
        "c1ad6290d50442488100632ba4c9c3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68d32554cd11448989b40fb6acc6bdb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbc7c7c580544f84ac68b1db7c76c32b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1198122,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1198122,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed55a5e6c18d48199dcf6caf7f9acce9"
          }
        },
        "8a80e8cb6c014590bfaff809e37219f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d09770f3cdf459c8bbf6e479b92b663",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20M/1.20M [00:01&lt;00:00, 845kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dae014d379ee4d97947e40d8c83862f3"
          }
        },
        "cbc7c7c580544f84ac68b1db7c76c32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed55a5e6c18d48199dcf6caf7f9acce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d09770f3cdf459c8bbf6e479b92b663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dae014d379ee4d97947e40d8c83862f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01fed2083c8f41ec942a8651f4d8571b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3f26798321cc4a09b4ce9a2696395fbe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5868507df6f44ee1b265857636f330de",
              "IPY_MODEL_06625d7c1a024832809eddf4458ab5c7"
            ]
          }
        },
        "3f26798321cc4a09b4ce9a2696395fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5868507df6f44ee1b265857636f330de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad1493167e9c4fe1bc37d5bcab49c65e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 963211760,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 963211760,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c27148e2ed2c46d2bbf756c1d7f37652"
          }
        },
        "06625d7c1a024832809eddf4458ab5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb968689513f4c689c4a0b2fce4af2b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 963M/963M [00:23&lt;00:00, 40.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4df00a402cbb407a9fe7ef0bdfe0075d"
          }
        },
        "ad1493167e9c4fe1bc37d5bcab49c65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c27148e2ed2c46d2bbf756c1d7f37652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb968689513f4c689c4a0b2fce4af2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4df00a402cbb407a9fe7ef0bdfe0075d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HLTT14/NLP-Assignments/blob/main/NLP_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUmCJcRJh9Kn"
      },
      "source": [
        "# **Gender Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x04WXPVLjaEw"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPkEQMmP2nNq",
        "outputId": "9553dd2f-9797-4231-d3c9-53fbd3d261ce"
      },
      "source": [
        "!git clone https://github.com/HLTT14/NLP-Assignments.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Assignments'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 54 (delta 26), reused 5 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPpAI9Ia5ELU",
        "outputId": "057804f9-c870-4c19-e4f7-86fc1e3abe8d"
      },
      "source": [
        "!unzip -o /content/NLP-Assignments/train.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/NLP-Assignments/train.zip\n",
            "   creating: train/\n",
            "   creating: train/female/\n",
            "  inflating: train/female/1.txt      \n",
            "  inflating: train/female/10.txt     \n",
            "  inflating: train/female/100.txt    \n",
            "  inflating: train/female/1000.txt   \n",
            "  inflating: train/female/101.txt    \n",
            "  inflating: train/female/102.txt    \n",
            "  inflating: train/female/103.txt    \n",
            "  inflating: train/female/104.txt    \n",
            "  inflating: train/female/105.txt    \n",
            "  inflating: train/female/106.txt    \n",
            "  inflating: train/female/107.txt    \n",
            "  inflating: train/female/108.txt    \n",
            "  inflating: train/female/109.txt    \n",
            "  inflating: train/female/11.txt     \n",
            "  inflating: train/female/110.txt    \n",
            "  inflating: train/female/111.txt    \n",
            "  inflating: train/female/112.txt    \n",
            "  inflating: train/female/113.txt    \n",
            "  inflating: train/female/114.txt    \n",
            "  inflating: train/female/115.txt    \n",
            "  inflating: train/female/116.txt    \n",
            "  inflating: train/female/117.txt    \n",
            "  inflating: train/female/118.txt    \n",
            "  inflating: train/female/119.txt    \n",
            "  inflating: train/female/12.txt     \n",
            "  inflating: train/female/120.txt    \n",
            "  inflating: train/female/121.txt    \n",
            "  inflating: train/female/122.txt    \n",
            "  inflating: train/female/123.txt    \n",
            "  inflating: train/female/124.txt    \n",
            "  inflating: train/female/125.txt    \n",
            "  inflating: train/female/126.txt    \n",
            "  inflating: train/female/127.txt    \n",
            "  inflating: train/female/128.txt    \n",
            "  inflating: train/female/129.txt    \n",
            "  inflating: train/female/13.txt     \n",
            "  inflating: train/female/130.txt    \n",
            "  inflating: train/female/131.txt    \n",
            "  inflating: train/female/132.txt    \n",
            "  inflating: train/female/133.txt    \n",
            "  inflating: train/female/134.txt    \n",
            "  inflating: train/female/135.txt    \n",
            "  inflating: train/female/136.txt    \n",
            "  inflating: train/female/137.txt    \n",
            "  inflating: train/female/138.txt    \n",
            "  inflating: train/female/139.txt    \n",
            "  inflating: train/female/14.txt     \n",
            "  inflating: train/female/140.txt    \n",
            "  inflating: train/female/141.txt    \n",
            "  inflating: train/female/142.txt    \n",
            "  inflating: train/female/143.txt    \n",
            "  inflating: train/female/144.txt    \n",
            "  inflating: train/female/145.txt    \n",
            "  inflating: train/female/146.txt    \n",
            "  inflating: train/female/147.txt    \n",
            "  inflating: train/female/148.txt    \n",
            "  inflating: train/female/149.txt    \n",
            "  inflating: train/female/15.txt     \n",
            "  inflating: train/female/150.txt    \n",
            "  inflating: train/female/151.txt    \n",
            "  inflating: train/female/152.txt    \n",
            "  inflating: train/female/153.txt    \n",
            "  inflating: train/female/154.txt    \n",
            "  inflating: train/female/155.txt    \n",
            "  inflating: train/female/156.txt    \n",
            "  inflating: train/female/157.txt    \n",
            "  inflating: train/female/158.txt    \n",
            "  inflating: train/female/159.txt    \n",
            "  inflating: train/female/16.txt     \n",
            "  inflating: train/female/160.txt    \n",
            "  inflating: train/female/161.txt    \n",
            "  inflating: train/female/162.txt    \n",
            "  inflating: train/female/163.txt    \n",
            "  inflating: train/female/164.txt    \n",
            "  inflating: train/female/165.txt    \n",
            "  inflating: train/female/166.txt    \n",
            "  inflating: train/female/167.txt    \n",
            "  inflating: train/female/168.txt    \n",
            "  inflating: train/female/169.txt    \n",
            "  inflating: train/female/17.txt     \n",
            "  inflating: train/female/170.txt    \n",
            "  inflating: train/female/171.txt    \n",
            "  inflating: train/female/172.txt    \n",
            "  inflating: train/female/173.txt    \n",
            "  inflating: train/female/174.txt    \n",
            "  inflating: train/female/175.txt    \n",
            "  inflating: train/female/176.txt    \n",
            "  inflating: train/female/177.txt    \n",
            "  inflating: train/female/178.txt    \n",
            "  inflating: train/female/179.txt    \n",
            "  inflating: train/female/18.txt     \n",
            "  inflating: train/female/180.txt    \n",
            "  inflating: train/female/181.txt    \n",
            "  inflating: train/female/182.txt    \n",
            "  inflating: train/female/183.txt    \n",
            "  inflating: train/female/184.txt    \n",
            "  inflating: train/female/185.txt    \n",
            "  inflating: train/female/186.txt    \n",
            "  inflating: train/female/187.txt    \n",
            "  inflating: train/female/188.txt    \n",
            "  inflating: train/female/189.txt    \n",
            "  inflating: train/female/19.txt     \n",
            "  inflating: train/female/190.txt    \n",
            "  inflating: train/female/191.txt    \n",
            "  inflating: train/female/192.txt    \n",
            "  inflating: train/female/193.txt    \n",
            "  inflating: train/female/194.txt    \n",
            "  inflating: train/female/195.txt    \n",
            "  inflating: train/female/196.txt    \n",
            "  inflating: train/female/197.txt    \n",
            "  inflating: train/female/198.txt    \n",
            "  inflating: train/female/199.txt    \n",
            "  inflating: train/female/2.txt      \n",
            "  inflating: train/female/20.txt     \n",
            "  inflating: train/female/200.txt    \n",
            "  inflating: train/female/201.txt    \n",
            "  inflating: train/female/202.txt    \n",
            "  inflating: train/female/203.txt    \n",
            "  inflating: train/female/204.txt    \n",
            "  inflating: train/female/205.txt    \n",
            "  inflating: train/female/206.txt    \n",
            "  inflating: train/female/207.txt    \n",
            "  inflating: train/female/208.txt    \n",
            "  inflating: train/female/209.txt    \n",
            "  inflating: train/female/21.txt     \n",
            "  inflating: train/female/210.txt    \n",
            "  inflating: train/female/211.txt    \n",
            "  inflating: train/female/212.txt    \n",
            "  inflating: train/female/213.txt    \n",
            "  inflating: train/female/214.txt    \n",
            "  inflating: train/female/215.txt    \n",
            "  inflating: train/female/216.txt    \n",
            "  inflating: train/female/217.txt    \n",
            "  inflating: train/female/218.txt    \n",
            "  inflating: train/female/219.txt    \n",
            "  inflating: train/female/22.txt     \n",
            "  inflating: train/female/220.txt    \n",
            "  inflating: train/female/221.txt    \n",
            "  inflating: train/female/222.txt    \n",
            "  inflating: train/female/223.txt    \n",
            "  inflating: train/female/224.txt    \n",
            "  inflating: train/female/225.txt    \n",
            "  inflating: train/female/226.txt    \n",
            "  inflating: train/female/227.txt    \n",
            "  inflating: train/female/228.txt    \n",
            "  inflating: train/female/229.txt    \n",
            "  inflating: train/female/23.txt     \n",
            "  inflating: train/female/230.txt    \n",
            "  inflating: train/female/231.txt    \n",
            "  inflating: train/female/232.txt    \n",
            "  inflating: train/female/233.txt    \n",
            "  inflating: train/female/234.txt    \n",
            "  inflating: train/female/235.txt    \n",
            "  inflating: train/female/236.txt    \n",
            "  inflating: train/female/237.txt    \n",
            "  inflating: train/female/238.txt    \n",
            "  inflating: train/female/239.txt    \n",
            "  inflating: train/female/24.txt     \n",
            "  inflating: train/female/240.txt    \n",
            "  inflating: train/female/241.txt    \n",
            "  inflating: train/female/242.txt    \n",
            "  inflating: train/female/243.txt    \n",
            "  inflating: train/female/244.txt    \n",
            "  inflating: train/female/245.txt    \n",
            "  inflating: train/female/246.txt    \n",
            "  inflating: train/female/247.txt    \n",
            "  inflating: train/female/248.txt    \n",
            "  inflating: train/female/249.txt    \n",
            "  inflating: train/female/25.txt     \n",
            "  inflating: train/female/250.txt    \n",
            "  inflating: train/female/251.txt    \n",
            "  inflating: train/female/252.txt    \n",
            "  inflating: train/female/253.txt    \n",
            "  inflating: train/female/254.txt    \n",
            "  inflating: train/female/255.txt    \n",
            "  inflating: train/female/256.txt    \n",
            "  inflating: train/female/257.txt    \n",
            "  inflating: train/female/258.txt    \n",
            "  inflating: train/female/259.txt    \n",
            "  inflating: train/female/26.txt     \n",
            "  inflating: train/female/260.txt    \n",
            "  inflating: train/female/261.txt    \n",
            "  inflating: train/female/262.txt    \n",
            "  inflating: train/female/263.txt    \n",
            "  inflating: train/female/264.txt    \n",
            "  inflating: train/female/265.txt    \n",
            "  inflating: train/female/266.txt    \n",
            "  inflating: train/female/267.txt    \n",
            "  inflating: train/female/268.txt    \n",
            "  inflating: train/female/269.txt    \n",
            "  inflating: train/female/27.txt     \n",
            "  inflating: train/female/270.txt    \n",
            "  inflating: train/female/271.txt    \n",
            "  inflating: train/female/272.txt    \n",
            "  inflating: train/female/273.txt    \n",
            "  inflating: train/female/274.txt    \n",
            "  inflating: train/female/275.txt    \n",
            "  inflating: train/female/276.txt    \n",
            "  inflating: train/female/277.txt    \n",
            "  inflating: train/female/278.txt    \n",
            "  inflating: train/female/279.txt    \n",
            "  inflating: train/female/28.txt     \n",
            "  inflating: train/female/280.txt    \n",
            "  inflating: train/female/281.txt    \n",
            "  inflating: train/female/282.txt    \n",
            "  inflating: train/female/283.txt    \n",
            "  inflating: train/female/284.txt    \n",
            "  inflating: train/female/285.txt    \n",
            "  inflating: train/female/286.txt    \n",
            "  inflating: train/female/287.txt    \n",
            "  inflating: train/female/288.txt    \n",
            "  inflating: train/female/289.txt    \n",
            "  inflating: train/female/29.txt     \n",
            "  inflating: train/female/290.txt    \n",
            "  inflating: train/female/291.txt    \n",
            "  inflating: train/female/292.txt    \n",
            "  inflating: train/female/293.txt    \n",
            "  inflating: train/female/294.txt    \n",
            "  inflating: train/female/295.txt    \n",
            "  inflating: train/female/296.txt    \n",
            "  inflating: train/female/297.txt    \n",
            "  inflating: train/female/298.txt    \n",
            "  inflating: train/female/299.txt    \n",
            "  inflating: train/female/3.txt      \n",
            "  inflating: train/female/30.txt     \n",
            "  inflating: train/female/300.txt    \n",
            "  inflating: train/female/301.txt    \n",
            "  inflating: train/female/302.txt    \n",
            "  inflating: train/female/303.txt    \n",
            "  inflating: train/female/304.txt    \n",
            "  inflating: train/female/305.txt    \n",
            "  inflating: train/female/306.txt    \n",
            "  inflating: train/female/307.txt    \n",
            "  inflating: train/female/308.txt    \n",
            "  inflating: train/female/309.txt    \n",
            "  inflating: train/female/31.txt     \n",
            "  inflating: train/female/310.txt    \n",
            "  inflating: train/female/311.txt    \n",
            "  inflating: train/female/312.txt    \n",
            "  inflating: train/female/313.txt    \n",
            "  inflating: train/female/314.txt    \n",
            "  inflating: train/female/315.txt    \n",
            "  inflating: train/female/316.txt    \n",
            "  inflating: train/female/317.txt    \n",
            "  inflating: train/female/318.txt    \n",
            "  inflating: train/female/319.txt    \n",
            "  inflating: train/female/32.txt     \n",
            "  inflating: train/female/320.txt    \n",
            "  inflating: train/female/321.txt    \n",
            "  inflating: train/female/322.txt    \n",
            "  inflating: train/female/323.txt    \n",
            "  inflating: train/female/324.txt    \n",
            "  inflating: train/female/325.txt    \n",
            "  inflating: train/female/326.txt    \n",
            "  inflating: train/female/327.txt    \n",
            "  inflating: train/female/328.txt    \n",
            "  inflating: train/female/329.txt    \n",
            "  inflating: train/female/33.txt     \n",
            "  inflating: train/female/330.txt    \n",
            "  inflating: train/female/331.txt    \n",
            "  inflating: train/female/332.txt    \n",
            "  inflating: train/female/333.txt    \n",
            "  inflating: train/female/334.txt    \n",
            "  inflating: train/female/335.txt    \n",
            "  inflating: train/female/336.txt    \n",
            "  inflating: train/female/337.txt    \n",
            "  inflating: train/female/338.txt    \n",
            "  inflating: train/female/339.txt    \n",
            "  inflating: train/female/34.txt     \n",
            "  inflating: train/female/340.txt    \n",
            "  inflating: train/female/341.txt    \n",
            "  inflating: train/female/342.txt    \n",
            "  inflating: train/female/343.txt    \n",
            "  inflating: train/female/344.txt    \n",
            "  inflating: train/female/345.txt    \n",
            "  inflating: train/female/346.txt    \n",
            "  inflating: train/female/347.txt    \n",
            "  inflating: train/female/348.txt    \n",
            "  inflating: train/female/349.txt    \n",
            "  inflating: train/female/35.txt     \n",
            "  inflating: train/female/350.txt    \n",
            "  inflating: train/female/351.txt    \n",
            "  inflating: train/female/352.txt    \n",
            "  inflating: train/female/353.txt    \n",
            "  inflating: train/female/354.txt    \n",
            "  inflating: train/female/355.txt    \n",
            "  inflating: train/female/356.txt    \n",
            "  inflating: train/female/357.txt    \n",
            "  inflating: train/female/358.txt    \n",
            "  inflating: train/female/359.txt    \n",
            "  inflating: train/female/36.txt     \n",
            "  inflating: train/female/360.txt    \n",
            "  inflating: train/female/361.txt    \n",
            "  inflating: train/female/362.txt    \n",
            "  inflating: train/female/363.txt    \n",
            "  inflating: train/female/364.txt    \n",
            "  inflating: train/female/365.txt    \n",
            "  inflating: train/female/366.txt    \n",
            "  inflating: train/female/367.txt    \n",
            "  inflating: train/female/368.txt    \n",
            "  inflating: train/female/369.txt    \n",
            "  inflating: train/female/37.txt     \n",
            "  inflating: train/female/370.txt    \n",
            "  inflating: train/female/371.txt    \n",
            "  inflating: train/female/372.txt    \n",
            "  inflating: train/female/373.txt    \n",
            "  inflating: train/female/374.txt    \n",
            "  inflating: train/female/375.txt    \n",
            "  inflating: train/female/376.txt    \n",
            "  inflating: train/female/377.txt    \n",
            "  inflating: train/female/378.txt    \n",
            "  inflating: train/female/379.txt    \n",
            "  inflating: train/female/38.txt     \n",
            "  inflating: train/female/380.txt    \n",
            "  inflating: train/female/381.txt    \n",
            "  inflating: train/female/382.txt    \n",
            "  inflating: train/female/383.txt    \n",
            "  inflating: train/female/384.txt    \n",
            "  inflating: train/female/385.txt    \n",
            "  inflating: train/female/386.txt    \n",
            "  inflating: train/female/387.txt    \n",
            "  inflating: train/female/388.txt    \n",
            "  inflating: train/female/389.txt    \n",
            "  inflating: train/female/39.txt     \n",
            "  inflating: train/female/390.txt    \n",
            "  inflating: train/female/391.txt    \n",
            "  inflating: train/female/392.txt    \n",
            "  inflating: train/female/393.txt    \n",
            "  inflating: train/female/394.txt    \n",
            "  inflating: train/female/395.txt    \n",
            "  inflating: train/female/396.txt    \n",
            "  inflating: train/female/397.txt    \n",
            "  inflating: train/female/398.txt    \n",
            "  inflating: train/female/399.txt    \n",
            "  inflating: train/female/4.txt      \n",
            "  inflating: train/female/40.txt     \n",
            "  inflating: train/female/400.txt    \n",
            "  inflating: train/female/401.txt    \n",
            "  inflating: train/female/402.txt    \n",
            "  inflating: train/female/403.txt    \n",
            "  inflating: train/female/404.txt    \n",
            "  inflating: train/female/405.txt    \n",
            "  inflating: train/female/406.txt    \n",
            "  inflating: train/female/407.txt    \n",
            "  inflating: train/female/408.txt    \n",
            "  inflating: train/female/409.txt    \n",
            "  inflating: train/female/41.txt     \n",
            "  inflating: train/female/410.txt    \n",
            "  inflating: train/female/411.txt    \n",
            "  inflating: train/female/412.txt    \n",
            "  inflating: train/female/413.txt    \n",
            "  inflating: train/female/414.txt    \n",
            "  inflating: train/female/415.txt    \n",
            "  inflating: train/female/416.txt    \n",
            "  inflating: train/female/417.txt    \n",
            "  inflating: train/female/418.txt    \n",
            "  inflating: train/female/419.txt    \n",
            "  inflating: train/female/42.txt     \n",
            "  inflating: train/female/420.txt    \n",
            "  inflating: train/female/421.txt    \n",
            "  inflating: train/female/422.txt    \n",
            "  inflating: train/female/423.txt    \n",
            "  inflating: train/female/424.txt    \n",
            "  inflating: train/female/425.txt    \n",
            "  inflating: train/female/426.txt    \n",
            "  inflating: train/female/427.txt    \n",
            "  inflating: train/female/428.txt    \n",
            "  inflating: train/female/429.txt    \n",
            "  inflating: train/female/43.txt     \n",
            "  inflating: train/female/430.txt    \n",
            "  inflating: train/female/431.txt    \n",
            "  inflating: train/female/432.txt    \n",
            "  inflating: train/female/433.txt    \n",
            "  inflating: train/female/434.txt    \n",
            "  inflating: train/female/435.txt    \n",
            "  inflating: train/female/436.txt    \n",
            "  inflating: train/female/437.txt    \n",
            "  inflating: train/female/438.txt    \n",
            "  inflating: train/female/439.txt    \n",
            "  inflating: train/female/44.txt     \n",
            "  inflating: train/female/440.txt    \n",
            "  inflating: train/female/441.txt    \n",
            "  inflating: train/female/442.txt    \n",
            "  inflating: train/female/443.txt    \n",
            "  inflating: train/female/444.txt    \n",
            "  inflating: train/female/445.txt    \n",
            "  inflating: train/female/446.txt    \n",
            "  inflating: train/female/447.txt    \n",
            "  inflating: train/female/448.txt    \n",
            "  inflating: train/female/449.txt    \n",
            "  inflating: train/female/45.txt     \n",
            "  inflating: train/female/450.txt    \n",
            "  inflating: train/female/451.txt    \n",
            "  inflating: train/female/452.txt    \n",
            "  inflating: train/female/453.txt    \n",
            "  inflating: train/female/454.txt    \n",
            "  inflating: train/female/455.txt    \n",
            "  inflating: train/female/456.txt    \n",
            "  inflating: train/female/457.txt    \n",
            "  inflating: train/female/458.txt    \n",
            "  inflating: train/female/459.txt    \n",
            "  inflating: train/female/46.txt     \n",
            "  inflating: train/female/460.txt    \n",
            "  inflating: train/female/461.txt    \n",
            "  inflating: train/female/462.txt    \n",
            "  inflating: train/female/463.txt    \n",
            "  inflating: train/female/464.txt    \n",
            "  inflating: train/female/465.txt    \n",
            "  inflating: train/female/466.txt    \n",
            "  inflating: train/female/467.txt    \n",
            "  inflating: train/female/468.txt    \n",
            "  inflating: train/female/469.txt    \n",
            "  inflating: train/female/47.txt     \n",
            "  inflating: train/female/470.txt    \n",
            "  inflating: train/female/471.txt    \n",
            "  inflating: train/female/472.txt    \n",
            "  inflating: train/female/473.txt    \n",
            "  inflating: train/female/474.txt    \n",
            "  inflating: train/female/475.txt    \n",
            "  inflating: train/female/476.txt    \n",
            "  inflating: train/female/477.txt    \n",
            "  inflating: train/female/478.txt    \n",
            "  inflating: train/female/479.txt    \n",
            "  inflating: train/female/48.txt     \n",
            "  inflating: train/female/480.txt    \n",
            "  inflating: train/female/481.txt    \n",
            "  inflating: train/female/482.txt    \n",
            "  inflating: train/female/483.txt    \n",
            "  inflating: train/female/484.txt    \n",
            "  inflating: train/female/485.txt    \n",
            "  inflating: train/female/486.txt    \n",
            "  inflating: train/female/487.txt    \n",
            "  inflating: train/female/488.txt    \n",
            "  inflating: train/female/489.txt    \n",
            "  inflating: train/female/49.txt     \n",
            "  inflating: train/female/490.txt    \n",
            "  inflating: train/female/491.txt    \n",
            "  inflating: train/female/492.txt    \n",
            "  inflating: train/female/493.txt    \n",
            "  inflating: train/female/494.txt    \n",
            "  inflating: train/female/495.txt    \n",
            "  inflating: train/female/496.txt    \n",
            "  inflating: train/female/497.txt    \n",
            "  inflating: train/female/498.txt    \n",
            "  inflating: train/female/499.txt    \n",
            "  inflating: train/female/5.txt      \n",
            "  inflating: train/female/50.txt     \n",
            "  inflating: train/female/500.txt    \n",
            "  inflating: train/female/501.txt    \n",
            "  inflating: train/female/502.txt    \n",
            "  inflating: train/female/503.txt    \n",
            "  inflating: train/female/504.txt    \n",
            "  inflating: train/female/505.txt    \n",
            "  inflating: train/female/506.txt    \n",
            "  inflating: train/female/507.txt    \n",
            "  inflating: train/female/508.txt    \n",
            "  inflating: train/female/509.txt    \n",
            "  inflating: train/female/51.txt     \n",
            "  inflating: train/female/510.txt    \n",
            "  inflating: train/female/511.txt    \n",
            "  inflating: train/female/512.txt    \n",
            "  inflating: train/female/513.txt    \n",
            "  inflating: train/female/514.txt    \n",
            "  inflating: train/female/515.txt    \n",
            "  inflating: train/female/516.txt    \n",
            "  inflating: train/female/517.txt    \n",
            "  inflating: train/female/518.txt    \n",
            "  inflating: train/female/519.txt    \n",
            "  inflating: train/female/52.txt     \n",
            "  inflating: train/female/520.txt    \n",
            "  inflating: train/female/521.txt    \n",
            "  inflating: train/female/522.txt    \n",
            "  inflating: train/female/523.txt    \n",
            "  inflating: train/female/524.txt    \n",
            "  inflating: train/female/525.txt    \n",
            "  inflating: train/female/526.txt    \n",
            "  inflating: train/female/527.txt    \n",
            "  inflating: train/female/528.txt    \n",
            "  inflating: train/female/529.txt    \n",
            "  inflating: train/female/53.txt     \n",
            "  inflating: train/female/530.txt    \n",
            "  inflating: train/female/531.txt    \n",
            "  inflating: train/female/532.txt    \n",
            "  inflating: train/female/533.txt    \n",
            "  inflating: train/female/534.txt    \n",
            "  inflating: train/female/535.txt    \n",
            "  inflating: train/female/536.txt    \n",
            "  inflating: train/female/537.txt    \n",
            "  inflating: train/female/538.txt    \n",
            "  inflating: train/female/539.txt    \n",
            "  inflating: train/female/54.txt     \n",
            "  inflating: train/female/540.txt    \n",
            "  inflating: train/female/541.txt    \n",
            "  inflating: train/female/542.txt    \n",
            "  inflating: train/female/543.txt    \n",
            "  inflating: train/female/544.txt    \n",
            "  inflating: train/female/545.txt    \n",
            "  inflating: train/female/546.txt    \n",
            "  inflating: train/female/547.txt    \n",
            "  inflating: train/female/548.txt    \n",
            "  inflating: train/female/549.txt    \n",
            "  inflating: train/female/55.txt     \n",
            "  inflating: train/female/550.txt    \n",
            "  inflating: train/female/551.txt    \n",
            "  inflating: train/female/552.txt    \n",
            "  inflating: train/female/553.txt    \n",
            "  inflating: train/female/554.txt    \n",
            "  inflating: train/female/555.txt    \n",
            "  inflating: train/female/556.txt    \n",
            "  inflating: train/female/557.txt    \n",
            "  inflating: train/female/558.txt    \n",
            "  inflating: train/female/559.txt    \n",
            "  inflating: train/female/56.txt     \n",
            "  inflating: train/female/560.txt    \n",
            "  inflating: train/female/561.txt    \n",
            "  inflating: train/female/562.txt    \n",
            "  inflating: train/female/563.txt    \n",
            "  inflating: train/female/564.txt    \n",
            "  inflating: train/female/565.txt    \n",
            "  inflating: train/female/566.txt    \n",
            "  inflating: train/female/567.txt    \n",
            "  inflating: train/female/568.txt    \n",
            "  inflating: train/female/569.txt    \n",
            "  inflating: train/female/57.txt     \n",
            "  inflating: train/female/570.txt    \n",
            "  inflating: train/female/571.txt    \n",
            "  inflating: train/female/572.txt    \n",
            "  inflating: train/female/573.txt    \n",
            "  inflating: train/female/574.txt    \n",
            "  inflating: train/female/575.txt    \n",
            "  inflating: train/female/576.txt    \n",
            "  inflating: train/female/577.txt    \n",
            "  inflating: train/female/578.txt    \n",
            "  inflating: train/female/579.txt    \n",
            "  inflating: train/female/58.txt     \n",
            "  inflating: train/female/580.txt    \n",
            "  inflating: train/female/581.txt    \n",
            "  inflating: train/female/582.txt    \n",
            "  inflating: train/female/583.txt    \n",
            "  inflating: train/female/584.txt    \n",
            "  inflating: train/female/585.txt    \n",
            "  inflating: train/female/586.txt    \n",
            "  inflating: train/female/587.txt    \n",
            "  inflating: train/female/588.txt    \n",
            "  inflating: train/female/589.txt    \n",
            "  inflating: train/female/59.txt     \n",
            "  inflating: train/female/590.txt    \n",
            "  inflating: train/female/591.txt    \n",
            "  inflating: train/female/592.txt    \n",
            "  inflating: train/female/593.txt    \n",
            "  inflating: train/female/594.txt    \n",
            "  inflating: train/female/595.txt    \n",
            "  inflating: train/female/596.txt    \n",
            "  inflating: train/female/597.txt    \n",
            "  inflating: train/female/598.txt    \n",
            "  inflating: train/female/599.txt    \n",
            "  inflating: train/female/6.txt      \n",
            "  inflating: train/female/60.txt     \n",
            "  inflating: train/female/600.txt    \n",
            "  inflating: train/female/601.txt    \n",
            "  inflating: train/female/602.txt    \n",
            "  inflating: train/female/603.txt    \n",
            "  inflating: train/female/604.txt    \n",
            "  inflating: train/female/605.txt    \n",
            "  inflating: train/female/606.txt    \n",
            "  inflating: train/female/607.txt    \n",
            "  inflating: train/female/608.txt    \n",
            "  inflating: train/female/609.txt    \n",
            "  inflating: train/female/61.txt     \n",
            "  inflating: train/female/610.txt    \n",
            "  inflating: train/female/611.txt    \n",
            "  inflating: train/female/612.txt    \n",
            "  inflating: train/female/613.txt    \n",
            "  inflating: train/female/614.txt    \n",
            "  inflating: train/female/615.txt    \n",
            "  inflating: train/female/616.txt    \n",
            "  inflating: train/female/617.txt    \n",
            "  inflating: train/female/618.txt    \n",
            "  inflating: train/female/619.txt    \n",
            "  inflating: train/female/62.txt     \n",
            "  inflating: train/female/620.txt    \n",
            "  inflating: train/female/621.txt    \n",
            "  inflating: train/female/622.txt    \n",
            "  inflating: train/female/623.txt    \n",
            "  inflating: train/female/624.txt    \n",
            "  inflating: train/female/625.txt    \n",
            "  inflating: train/female/626.txt    \n",
            "  inflating: train/female/627.txt    \n",
            "  inflating: train/female/628.txt    \n",
            "  inflating: train/female/629.txt    \n",
            "  inflating: train/female/63.txt     \n",
            "  inflating: train/female/630.txt    \n",
            "  inflating: train/female/631.txt    \n",
            "  inflating: train/female/632.txt    \n",
            "  inflating: train/female/633.txt    \n",
            "  inflating: train/female/634.txt    \n",
            "  inflating: train/female/635.txt    \n",
            "  inflating: train/female/636.txt    \n",
            "  inflating: train/female/637.txt    \n",
            "  inflating: train/female/638.txt    \n",
            "  inflating: train/female/639.txt    \n",
            "  inflating: train/female/64.txt     \n",
            "  inflating: train/female/640.txt    \n",
            "  inflating: train/female/641.txt    \n",
            "  inflating: train/female/642.txt    \n",
            "  inflating: train/female/643.txt    \n",
            "  inflating: train/female/644.txt    \n",
            "  inflating: train/female/645.txt    \n",
            "  inflating: train/female/646.txt    \n",
            "  inflating: train/female/647.txt    \n",
            "  inflating: train/female/648.txt    \n",
            "  inflating: train/female/649.txt    \n",
            "  inflating: train/female/65.txt     \n",
            "  inflating: train/female/650.txt    \n",
            "  inflating: train/female/651.txt    \n",
            "  inflating: train/female/652.txt    \n",
            "  inflating: train/female/653.txt    \n",
            "  inflating: train/female/654.txt    \n",
            "  inflating: train/female/655.txt    \n",
            "  inflating: train/female/656.txt    \n",
            "  inflating: train/female/657.txt    \n",
            "  inflating: train/female/658.txt    \n",
            "  inflating: train/female/659.txt    \n",
            "  inflating: train/female/66.txt     \n",
            "  inflating: train/female/660.txt    \n",
            "  inflating: train/female/661.txt    \n",
            "  inflating: train/female/662.txt    \n",
            "  inflating: train/female/663.txt    \n",
            "  inflating: train/female/664.txt    \n",
            "  inflating: train/female/665.txt    \n",
            "  inflating: train/female/666.txt    \n",
            "  inflating: train/female/667.txt    \n",
            "  inflating: train/female/668.txt    \n",
            "  inflating: train/female/669.txt    \n",
            "  inflating: train/female/67.txt     \n",
            "  inflating: train/female/670.txt    \n",
            "  inflating: train/female/671.txt    \n",
            "  inflating: train/female/672.txt    \n",
            "  inflating: train/female/673.txt    \n",
            "  inflating: train/female/674.txt    \n",
            "  inflating: train/female/675.txt    \n",
            "  inflating: train/female/676.txt    \n",
            "  inflating: train/female/677.txt    \n",
            "  inflating: train/female/678.txt    \n",
            "  inflating: train/female/679.txt    \n",
            "  inflating: train/female/68.txt     \n",
            "  inflating: train/female/680.txt    \n",
            "  inflating: train/female/681.txt    \n",
            "  inflating: train/female/682.txt    \n",
            "  inflating: train/female/683.txt    \n",
            "  inflating: train/female/684.txt    \n",
            "  inflating: train/female/685.txt    \n",
            "  inflating: train/female/686.txt    \n",
            "  inflating: train/female/687.txt    \n",
            "  inflating: train/female/688.txt    \n",
            "  inflating: train/female/689.txt    \n",
            "  inflating: train/female/69.txt     \n",
            "  inflating: train/female/690.txt    \n",
            "  inflating: train/female/691.txt    \n",
            "  inflating: train/female/692.txt    \n",
            "  inflating: train/female/693.txt    \n",
            "  inflating: train/female/694.txt    \n",
            "  inflating: train/female/695.txt    \n",
            "  inflating: train/female/696.txt    \n",
            "  inflating: train/female/697.txt    \n",
            "  inflating: train/female/698.txt    \n",
            "  inflating: train/female/699.txt    \n",
            "  inflating: train/female/7.txt      \n",
            "  inflating: train/female/70.txt     \n",
            "  inflating: train/female/700.txt    \n",
            "  inflating: train/female/701.txt    \n",
            "  inflating: train/female/702.txt    \n",
            "  inflating: train/female/703.txt    \n",
            "  inflating: train/female/704.txt    \n",
            "  inflating: train/female/705.txt    \n",
            "  inflating: train/female/706.txt    \n",
            "  inflating: train/female/707.txt    \n",
            "  inflating: train/female/708.txt    \n",
            "  inflating: train/female/709.txt    \n",
            "  inflating: train/female/71.txt     \n",
            "  inflating: train/female/710.txt    \n",
            "  inflating: train/female/711.txt    \n",
            "  inflating: train/female/712.txt    \n",
            "  inflating: train/female/713.txt    \n",
            "  inflating: train/female/714.txt    \n",
            "  inflating: train/female/715.txt    \n",
            "  inflating: train/female/716.txt    \n",
            "  inflating: train/female/717.txt    \n",
            "  inflating: train/female/718.txt    \n",
            "  inflating: train/female/719.txt    \n",
            "  inflating: train/female/72.txt     \n",
            "  inflating: train/female/720.txt    \n",
            "  inflating: train/female/721.txt    \n",
            "  inflating: train/female/722.txt    \n",
            "  inflating: train/female/723.txt    \n",
            "  inflating: train/female/724.txt    \n",
            "  inflating: train/female/725.txt    \n",
            "  inflating: train/female/726.txt    \n",
            "  inflating: train/female/727.txt    \n",
            "  inflating: train/female/728.txt    \n",
            "  inflating: train/female/729.txt    \n",
            "  inflating: train/female/73.txt     \n",
            "  inflating: train/female/730.txt    \n",
            "  inflating: train/female/731.txt    \n",
            "  inflating: train/female/732.txt    \n",
            "  inflating: train/female/733.txt    \n",
            "  inflating: train/female/734.txt    \n",
            "  inflating: train/female/735.txt    \n",
            "  inflating: train/female/736.txt    \n",
            "  inflating: train/female/737.txt    \n",
            "  inflating: train/female/738.txt    \n",
            "  inflating: train/female/739.txt    \n",
            "  inflating: train/female/74.txt     \n",
            "  inflating: train/female/740.txt    \n",
            "  inflating: train/female/741.txt    \n",
            "  inflating: train/female/742.txt    \n",
            "  inflating: train/female/743.txt    \n",
            "  inflating: train/female/744.txt    \n",
            "  inflating: train/female/745.txt    \n",
            "  inflating: train/female/746.txt    \n",
            "  inflating: train/female/747.txt    \n",
            "  inflating: train/female/748.txt    \n",
            "  inflating: train/female/749.txt    \n",
            "  inflating: train/female/75.txt     \n",
            "  inflating: train/female/750.txt    \n",
            "  inflating: train/female/751.txt    \n",
            "  inflating: train/female/752.txt    \n",
            "  inflating: train/female/753.txt    \n",
            "  inflating: train/female/754.txt    \n",
            "  inflating: train/female/755.txt    \n",
            "  inflating: train/female/756.txt    \n",
            "  inflating: train/female/757.txt    \n",
            "  inflating: train/female/758.txt    \n",
            "  inflating: train/female/759.txt    \n",
            "  inflating: train/female/76.txt     \n",
            "  inflating: train/female/760.txt    \n",
            "  inflating: train/female/761.txt    \n",
            "  inflating: train/female/762.txt    \n",
            "  inflating: train/female/763.txt    \n",
            "  inflating: train/female/764.txt    \n",
            "  inflating: train/female/765.txt    \n",
            "  inflating: train/female/766.txt    \n",
            "  inflating: train/female/767.txt    \n",
            "  inflating: train/female/768.txt    \n",
            "  inflating: train/female/769.txt    \n",
            "  inflating: train/female/77.txt     \n",
            "  inflating: train/female/770.txt    \n",
            "  inflating: train/female/771.txt    \n",
            "  inflating: train/female/772.txt    \n",
            "  inflating: train/female/773.txt    \n",
            "  inflating: train/female/774.txt    \n",
            "  inflating: train/female/775.txt    \n",
            "  inflating: train/female/776.txt    \n",
            "  inflating: train/female/777.txt    \n",
            "  inflating: train/female/778.txt    \n",
            "  inflating: train/female/779.txt    \n",
            "  inflating: train/female/78.txt     \n",
            "  inflating: train/female/780.txt    \n",
            "  inflating: train/female/781.txt    \n",
            "  inflating: train/female/782.txt    \n",
            "  inflating: train/female/783.txt    \n",
            "  inflating: train/female/784.txt    \n",
            "  inflating: train/female/785.txt    \n",
            "  inflating: train/female/786.txt    \n",
            "  inflating: train/female/787.txt    \n",
            "  inflating: train/female/788.txt    \n",
            "  inflating: train/female/789.txt    \n",
            "  inflating: train/female/79.txt     \n",
            "  inflating: train/female/790.txt    \n",
            "  inflating: train/female/791.txt    \n",
            "  inflating: train/female/792.txt    \n",
            "  inflating: train/female/793.txt    \n",
            "  inflating: train/female/794.txt    \n",
            "  inflating: train/female/795.txt    \n",
            "  inflating: train/female/796.txt    \n",
            "  inflating: train/female/797.txt    \n",
            "  inflating: train/female/798.txt    \n",
            "  inflating: train/female/799.txt    \n",
            "  inflating: train/female/8.txt      \n",
            "  inflating: train/female/80.txt     \n",
            "  inflating: train/female/800.txt    \n",
            "  inflating: train/female/801.txt    \n",
            "  inflating: train/female/802.txt    \n",
            "  inflating: train/female/803.txt    \n",
            "  inflating: train/female/804.txt    \n",
            "  inflating: train/female/805.txt    \n",
            "  inflating: train/female/806.txt    \n",
            "  inflating: train/female/807.txt    \n",
            "  inflating: train/female/808.txt    \n",
            "  inflating: train/female/809.txt    \n",
            "  inflating: train/female/81.txt     \n",
            "  inflating: train/female/810.txt    \n",
            "  inflating: train/female/811.txt    \n",
            "  inflating: train/female/812.txt    \n",
            "  inflating: train/female/813.txt    \n",
            "  inflating: train/female/814.txt    \n",
            "  inflating: train/female/815.txt    \n",
            "  inflating: train/female/816.txt    \n",
            "  inflating: train/female/817.txt    \n",
            "  inflating: train/female/818.txt    \n",
            "  inflating: train/female/819.txt    \n",
            "  inflating: train/female/82.txt     \n",
            "  inflating: train/female/820.txt    \n",
            "  inflating: train/female/821.txt    \n",
            "  inflating: train/female/822.txt    \n",
            "  inflating: train/female/823.txt    \n",
            "  inflating: train/female/824.txt    \n",
            "  inflating: train/female/825.txt    \n",
            "  inflating: train/female/826.txt    \n",
            "  inflating: train/female/827.txt    \n",
            "  inflating: train/female/828.txt    \n",
            "  inflating: train/female/829.txt    \n",
            "  inflating: train/female/83.txt     \n",
            "  inflating: train/female/830.txt    \n",
            "  inflating: train/female/831.txt    \n",
            "  inflating: train/female/832.txt    \n",
            "  inflating: train/female/833.txt    \n",
            "  inflating: train/female/834.txt    \n",
            "  inflating: train/female/835.txt    \n",
            "  inflating: train/female/836.txt    \n",
            "  inflating: train/female/837.txt    \n",
            "  inflating: train/female/838.txt    \n",
            "  inflating: train/female/839.txt    \n",
            "  inflating: train/female/84.txt     \n",
            "  inflating: train/female/840.txt    \n",
            "  inflating: train/female/841.txt    \n",
            "  inflating: train/female/842.txt    \n",
            "  inflating: train/female/843.txt    \n",
            "  inflating: train/female/844.txt    \n",
            "  inflating: train/female/845.txt    \n",
            "  inflating: train/female/846.txt    \n",
            "  inflating: train/female/847.txt    \n",
            "  inflating: train/female/848.txt    \n",
            "  inflating: train/female/849.txt    \n",
            "  inflating: train/female/85.txt     \n",
            "  inflating: train/female/850.txt    \n",
            "  inflating: train/female/851.txt    \n",
            "  inflating: train/female/852.txt    \n",
            "  inflating: train/female/853.txt    \n",
            "  inflating: train/female/854.txt    \n",
            "  inflating: train/female/855.txt    \n",
            "  inflating: train/female/856.txt    \n",
            "  inflating: train/female/857.txt    \n",
            "  inflating: train/female/858.txt    \n",
            "  inflating: train/female/859.txt    \n",
            "  inflating: train/female/86.txt     \n",
            "  inflating: train/female/860.txt    \n",
            "  inflating: train/female/861.txt    \n",
            "  inflating: train/female/862.txt    \n",
            "  inflating: train/female/863.txt    \n",
            "  inflating: train/female/864.txt    \n",
            "  inflating: train/female/865.txt    \n",
            "  inflating: train/female/866.txt    \n",
            "  inflating: train/female/867.txt    \n",
            "  inflating: train/female/868.txt    \n",
            "  inflating: train/female/869.txt    \n",
            "  inflating: train/female/87.txt     \n",
            "  inflating: train/female/870.txt    \n",
            "  inflating: train/female/871.txt    \n",
            "  inflating: train/female/872.txt    \n",
            "  inflating: train/female/873.txt    \n",
            "  inflating: train/female/874.txt    \n",
            "  inflating: train/female/875.txt    \n",
            "  inflating: train/female/876.txt    \n",
            "  inflating: train/female/877.txt    \n",
            "  inflating: train/female/878.txt    \n",
            "  inflating: train/female/879.txt    \n",
            "  inflating: train/female/88.txt     \n",
            "  inflating: train/female/880.txt    \n",
            "  inflating: train/female/881.txt    \n",
            "  inflating: train/female/882.txt    \n",
            "  inflating: train/female/883.txt    \n",
            "  inflating: train/female/884.txt    \n",
            "  inflating: train/female/885.txt    \n",
            "  inflating: train/female/886.txt    \n",
            "  inflating: train/female/887.txt    \n",
            "  inflating: train/female/888.txt    \n",
            "  inflating: train/female/889.txt    \n",
            "  inflating: train/female/89.txt     \n",
            "  inflating: train/female/890.txt    \n",
            "  inflating: train/female/891.txt    \n",
            "  inflating: train/female/892.txt    \n",
            "  inflating: train/female/893.txt    \n",
            "  inflating: train/female/894.txt    \n",
            "  inflating: train/female/895.txt    \n",
            "  inflating: train/female/896.txt    \n",
            "  inflating: train/female/897.txt    \n",
            "  inflating: train/female/898.txt    \n",
            "  inflating: train/female/899.txt    \n",
            "  inflating: train/female/9.txt      \n",
            "  inflating: train/female/90.txt     \n",
            "  inflating: train/female/900.txt    \n",
            "  inflating: train/female/901.txt    \n",
            "  inflating: train/female/902.txt    \n",
            "  inflating: train/female/903.txt    \n",
            "  inflating: train/female/904.txt    \n",
            "  inflating: train/female/905.txt    \n",
            "  inflating: train/female/906.txt    \n",
            "  inflating: train/female/907.txt    \n",
            "  inflating: train/female/908.txt    \n",
            "  inflating: train/female/909.txt    \n",
            "  inflating: train/female/91.txt     \n",
            "  inflating: train/female/910.txt    \n",
            "  inflating: train/female/911.txt    \n",
            "  inflating: train/female/912.txt    \n",
            "  inflating: train/female/913.txt    \n",
            "  inflating: train/female/914.txt    \n",
            "  inflating: train/female/915.txt    \n",
            "  inflating: train/female/916.txt    \n",
            "  inflating: train/female/917.txt    \n",
            "  inflating: train/female/918.txt    \n",
            "  inflating: train/female/919.txt    \n",
            "  inflating: train/female/92.txt     \n",
            "  inflating: train/female/920.txt    \n",
            "  inflating: train/female/921.txt    \n",
            "  inflating: train/female/922.txt    \n",
            "  inflating: train/female/923.txt    \n",
            "  inflating: train/female/924.txt    \n",
            "  inflating: train/female/925.txt    \n",
            "  inflating: train/female/926.txt    \n",
            "  inflating: train/female/927.txt    \n",
            "  inflating: train/female/928.txt    \n",
            "  inflating: train/female/929.txt    \n",
            "  inflating: train/female/93.txt     \n",
            "  inflating: train/female/930.txt    \n",
            "  inflating: train/female/931.txt    \n",
            "  inflating: train/female/932.txt    \n",
            "  inflating: train/female/933.txt    \n",
            "  inflating: train/female/934.txt    \n",
            "  inflating: train/female/935.txt    \n",
            "  inflating: train/female/936.txt    \n",
            "  inflating: train/female/937.txt    \n",
            "  inflating: train/female/938.txt    \n",
            "  inflating: train/female/939.txt    \n",
            "  inflating: train/female/94.txt     \n",
            "  inflating: train/female/940.txt    \n",
            "  inflating: train/female/941.txt    \n",
            "  inflating: train/female/942.txt    \n",
            "  inflating: train/female/943.txt    \n",
            "  inflating: train/female/944.txt    \n",
            "  inflating: train/female/945.txt    \n",
            "  inflating: train/female/946.txt    \n",
            "  inflating: train/female/947.txt    \n",
            "  inflating: train/female/948.txt    \n",
            "  inflating: train/female/949.txt    \n",
            "  inflating: train/female/95.txt     \n",
            "  inflating: train/female/950.txt    \n",
            "  inflating: train/female/951.txt    \n",
            "  inflating: train/female/952.txt    \n",
            "  inflating: train/female/953.txt    \n",
            "  inflating: train/female/954.txt    \n",
            "  inflating: train/female/955.txt    \n",
            "  inflating: train/female/956.txt    \n",
            "  inflating: train/female/957.txt    \n",
            "  inflating: train/female/958.txt    \n",
            "  inflating: train/female/959.txt    \n",
            "  inflating: train/female/96.txt     \n",
            "  inflating: train/female/960.txt    \n",
            "  inflating: train/female/961.txt    \n",
            "  inflating: train/female/962.txt    \n",
            "  inflating: train/female/963.txt    \n",
            "  inflating: train/female/964.txt    \n",
            "  inflating: train/female/965.txt    \n",
            "  inflating: train/female/966.txt    \n",
            "  inflating: train/female/967.txt    \n",
            "  inflating: train/female/968.txt    \n",
            "  inflating: train/female/969.txt    \n",
            "  inflating: train/female/97.txt     \n",
            "  inflating: train/female/970.txt    \n",
            "  inflating: train/female/971.txt    \n",
            "  inflating: train/female/972.txt    \n",
            "  inflating: train/female/973.txt    \n",
            "  inflating: train/female/974.txt    \n",
            "  inflating: train/female/975.txt    \n",
            "  inflating: train/female/976.txt    \n",
            "  inflating: train/female/977.txt    \n",
            "  inflating: train/female/978.txt    \n",
            "  inflating: train/female/979.txt    \n",
            "  inflating: train/female/98.txt     \n",
            "  inflating: train/female/980.txt    \n",
            "  inflating: train/female/981.txt    \n",
            "  inflating: train/female/982.txt    \n",
            "  inflating: train/female/983.txt    \n",
            "  inflating: train/female/984.txt    \n",
            "  inflating: train/female/985.txt    \n",
            "  inflating: train/female/986.txt    \n",
            "  inflating: train/female/987.txt    \n",
            "  inflating: train/female/988.txt    \n",
            "  inflating: train/female/989.txt    \n",
            "  inflating: train/female/99.txt     \n",
            "  inflating: train/female/990.txt    \n",
            "  inflating: train/female/991.txt    \n",
            "  inflating: train/female/992.txt    \n",
            "  inflating: train/female/993.txt    \n",
            "  inflating: train/female/994.txt    \n",
            "  inflating: train/female/995.txt    \n",
            "  inflating: train/female/996.txt    \n",
            "  inflating: train/female/997.txt    \n",
            "  inflating: train/female/998.txt    \n",
            "  inflating: train/female/999.txt    \n",
            "   creating: train/male/\n",
            "  inflating: train/male/1.txt        \n",
            "  inflating: train/male/10.txt       \n",
            "  inflating: train/male/100.txt      \n",
            "  inflating: train/male/1000.txt     \n",
            "  inflating: train/male/101.txt      \n",
            "  inflating: train/male/102.txt      \n",
            "  inflating: train/male/103.txt      \n",
            "  inflating: train/male/104.txt      \n",
            "  inflating: train/male/105.txt      \n",
            "  inflating: train/male/106.txt      \n",
            "  inflating: train/male/107.txt      \n",
            "  inflating: train/male/108.txt      \n",
            "  inflating: train/male/109.txt      \n",
            "  inflating: train/male/11.txt       \n",
            "  inflating: train/male/110.txt      \n",
            "  inflating: train/male/111.txt      \n",
            "  inflating: train/male/112.txt      \n",
            "  inflating: train/male/113.txt      \n",
            "  inflating: train/male/114.txt      \n",
            "  inflating: train/male/115.txt      \n",
            "  inflating: train/male/116.txt      \n",
            "  inflating: train/male/117.txt      \n",
            "  inflating: train/male/118.txt      \n",
            "  inflating: train/male/119.txt      \n",
            "  inflating: train/male/12.txt       \n",
            "  inflating: train/male/120.txt      \n",
            "  inflating: train/male/121.txt      \n",
            "  inflating: train/male/122.txt      \n",
            "  inflating: train/male/123.txt      \n",
            "  inflating: train/male/124.txt      \n",
            "  inflating: train/male/125.txt      \n",
            "  inflating: train/male/126.txt      \n",
            "  inflating: train/male/127.txt      \n",
            "  inflating: train/male/128.txt      \n",
            "  inflating: train/male/129.txt      \n",
            "  inflating: train/male/13.txt       \n",
            "  inflating: train/male/130.txt      \n",
            "  inflating: train/male/131.txt      \n",
            "  inflating: train/male/132.txt      \n",
            "  inflating: train/male/133.txt      \n",
            "  inflating: train/male/134.txt      \n",
            "  inflating: train/male/135.txt      \n",
            "  inflating: train/male/136.txt      \n",
            "  inflating: train/male/137.txt      \n",
            "  inflating: train/male/138.txt      \n",
            "  inflating: train/male/139.txt      \n",
            "  inflating: train/male/14.txt       \n",
            "  inflating: train/male/140.txt      \n",
            "  inflating: train/male/141.txt      \n",
            "  inflating: train/male/142.txt      \n",
            "  inflating: train/male/143.txt      \n",
            "  inflating: train/male/144.txt      \n",
            "  inflating: train/male/145.txt      \n",
            "  inflating: train/male/146.txt      \n",
            "  inflating: train/male/147.txt      \n",
            "  inflating: train/male/148.txt      \n",
            "  inflating: train/male/149.txt      \n",
            "  inflating: train/male/15.txt       \n",
            "  inflating: train/male/150.txt      \n",
            "  inflating: train/male/151.txt      \n",
            "  inflating: train/male/152.txt      \n",
            "  inflating: train/male/153.txt      \n",
            "  inflating: train/male/154.txt      \n",
            "  inflating: train/male/155.txt      \n",
            "  inflating: train/male/156.txt      \n",
            "  inflating: train/male/157.txt      \n",
            "  inflating: train/male/158.txt      \n",
            "  inflating: train/male/159.txt      \n",
            "  inflating: train/male/16.txt       \n",
            "  inflating: train/male/160.txt      \n",
            "  inflating: train/male/161.txt      \n",
            "  inflating: train/male/162.txt      \n",
            "  inflating: train/male/163.txt      \n",
            "  inflating: train/male/164.txt      \n",
            "  inflating: train/male/165.txt      \n",
            "  inflating: train/male/166.txt      \n",
            "  inflating: train/male/167.txt      \n",
            "  inflating: train/male/168.txt      \n",
            "  inflating: train/male/169.txt      \n",
            "  inflating: train/male/17.txt       \n",
            "  inflating: train/male/170.txt      \n",
            "  inflating: train/male/171.txt      \n",
            "  inflating: train/male/172.txt      \n",
            "  inflating: train/male/173.txt      \n",
            "  inflating: train/male/174.txt      \n",
            "  inflating: train/male/175.txt      \n",
            "  inflating: train/male/176.txt      \n",
            "  inflating: train/male/177.txt      \n",
            "  inflating: train/male/178.txt      \n",
            "  inflating: train/male/179.txt      \n",
            "  inflating: train/male/18.txt       \n",
            "  inflating: train/male/180.txt      \n",
            "  inflating: train/male/181.txt      \n",
            "  inflating: train/male/182.txt      \n",
            "  inflating: train/male/183.txt      \n",
            "  inflating: train/male/184.txt      \n",
            "  inflating: train/male/185.txt      \n",
            "  inflating: train/male/186.txt      \n",
            "  inflating: train/male/187.txt      \n",
            "  inflating: train/male/188.txt      \n",
            "  inflating: train/male/189.txt      \n",
            "  inflating: train/male/19.txt       \n",
            "  inflating: train/male/190.txt      \n",
            "  inflating: train/male/191.txt      \n",
            "  inflating: train/male/192.txt      \n",
            "  inflating: train/male/193.txt      \n",
            "  inflating: train/male/194.txt      \n",
            "  inflating: train/male/195.txt      \n",
            "  inflating: train/male/196.txt      \n",
            "  inflating: train/male/197.txt      \n",
            "  inflating: train/male/198.txt      \n",
            "  inflating: train/male/199.txt      \n",
            "  inflating: train/male/2.txt        \n",
            "  inflating: train/male/20.txt       \n",
            "  inflating: train/male/200.txt      \n",
            "  inflating: train/male/201.txt      \n",
            "  inflating: train/male/202.txt      \n",
            "  inflating: train/male/203.txt      \n",
            "  inflating: train/male/204.txt      \n",
            "  inflating: train/male/205.txt      \n",
            "  inflating: train/male/206.txt      \n",
            "  inflating: train/male/207.txt      \n",
            "  inflating: train/male/208.txt      \n",
            "  inflating: train/male/209.txt      \n",
            "  inflating: train/male/21.txt       \n",
            "  inflating: train/male/210.txt      \n",
            "  inflating: train/male/211.txt      \n",
            "  inflating: train/male/212.txt      \n",
            "  inflating: train/male/213.txt      \n",
            "  inflating: train/male/214.txt      \n",
            "  inflating: train/male/215.txt      \n",
            "  inflating: train/male/216.txt      \n",
            "  inflating: train/male/217.txt      \n",
            "  inflating: train/male/218.txt      \n",
            "  inflating: train/male/219.txt      \n",
            "  inflating: train/male/22.txt       \n",
            "  inflating: train/male/220.txt      \n",
            "  inflating: train/male/221.txt      \n",
            "  inflating: train/male/222.txt      \n",
            "  inflating: train/male/223.txt      \n",
            "  inflating: train/male/224.txt      \n",
            "  inflating: train/male/225.txt      \n",
            "  inflating: train/male/226.txt      \n",
            "  inflating: train/male/227.txt      \n",
            "  inflating: train/male/228.txt      \n",
            "  inflating: train/male/229.txt      \n",
            "  inflating: train/male/23.txt       \n",
            "  inflating: train/male/230.txt      \n",
            "  inflating: train/male/231.txt      \n",
            "  inflating: train/male/232.txt      \n",
            "  inflating: train/male/233.txt      \n",
            "  inflating: train/male/234.txt      \n",
            "  inflating: train/male/235.txt      \n",
            "  inflating: train/male/236.txt      \n",
            "  inflating: train/male/237.txt      \n",
            "  inflating: train/male/238.txt      \n",
            "  inflating: train/male/239.txt      \n",
            "  inflating: train/male/24.txt       \n",
            "  inflating: train/male/240.txt      \n",
            "  inflating: train/male/241.txt      \n",
            "  inflating: train/male/242.txt      \n",
            "  inflating: train/male/243.txt      \n",
            "  inflating: train/male/244.txt      \n",
            "  inflating: train/male/245.txt      \n",
            "  inflating: train/male/246.txt      \n",
            "  inflating: train/male/247.txt      \n",
            "  inflating: train/male/248.txt      \n",
            "  inflating: train/male/249.txt      \n",
            "  inflating: train/male/25.txt       \n",
            "  inflating: train/male/250.txt      \n",
            "  inflating: train/male/251.txt      \n",
            "  inflating: train/male/252.txt      \n",
            "  inflating: train/male/253.txt      \n",
            "  inflating: train/male/254.txt      \n",
            "  inflating: train/male/255.txt      \n",
            "  inflating: train/male/256.txt      \n",
            "  inflating: train/male/257.txt      \n",
            "  inflating: train/male/258.txt      \n",
            "  inflating: train/male/259.txt      \n",
            "  inflating: train/male/26.txt       \n",
            "  inflating: train/male/260.txt      \n",
            "  inflating: train/male/261.txt      \n",
            "  inflating: train/male/262.txt      \n",
            "  inflating: train/male/263.txt      \n",
            "  inflating: train/male/264.txt      \n",
            "  inflating: train/male/265.txt      \n",
            "  inflating: train/male/266.txt      \n",
            "  inflating: train/male/267.txt      \n",
            "  inflating: train/male/268.txt      \n",
            "  inflating: train/male/269.txt      \n",
            "  inflating: train/male/27.txt       \n",
            "  inflating: train/male/270.txt      \n",
            "  inflating: train/male/271.txt      \n",
            "  inflating: train/male/272.txt      \n",
            "  inflating: train/male/273.txt      \n",
            "  inflating: train/male/274.txt      \n",
            "  inflating: train/male/275.txt      \n",
            "  inflating: train/male/276.txt      \n",
            "  inflating: train/male/277.txt      \n",
            "  inflating: train/male/278.txt      \n",
            "  inflating: train/male/279.txt      \n",
            "  inflating: train/male/28.txt       \n",
            "  inflating: train/male/280.txt      \n",
            "  inflating: train/male/281.txt      \n",
            "  inflating: train/male/282.txt      \n",
            "  inflating: train/male/283.txt      \n",
            "  inflating: train/male/284.txt      \n",
            "  inflating: train/male/285.txt      \n",
            "  inflating: train/male/286.txt      \n",
            "  inflating: train/male/287.txt      \n",
            "  inflating: train/male/288.txt      \n",
            "  inflating: train/male/289.txt      \n",
            "  inflating: train/male/29.txt       \n",
            "  inflating: train/male/290.txt      \n",
            "  inflating: train/male/291.txt      \n",
            "  inflating: train/male/292.txt      \n",
            "  inflating: train/male/293.txt      \n",
            "  inflating: train/male/294.txt      \n",
            "  inflating: train/male/295.txt      \n",
            "  inflating: train/male/296.txt      \n",
            "  inflating: train/male/297.txt      \n",
            "  inflating: train/male/298.txt      \n",
            "  inflating: train/male/299.txt      \n",
            "  inflating: train/male/3.txt        \n",
            "  inflating: train/male/30.txt       \n",
            "  inflating: train/male/300.txt      \n",
            "  inflating: train/male/301.txt      \n",
            "  inflating: train/male/302.txt      \n",
            "  inflating: train/male/303.txt      \n",
            "  inflating: train/male/304.txt      \n",
            "  inflating: train/male/305.txt      \n",
            "  inflating: train/male/306.txt      \n",
            "  inflating: train/male/307.txt      \n",
            "  inflating: train/male/308.txt      \n",
            "  inflating: train/male/309.txt      \n",
            "  inflating: train/male/31.txt       \n",
            "  inflating: train/male/310.txt      \n",
            "  inflating: train/male/311.txt      \n",
            "  inflating: train/male/312.txt      \n",
            "  inflating: train/male/313.txt      \n",
            "  inflating: train/male/314.txt      \n",
            "  inflating: train/male/315.txt      \n",
            "  inflating: train/male/316.txt      \n",
            "  inflating: train/male/317.txt      \n",
            "  inflating: train/male/318.txt      \n",
            "  inflating: train/male/319.txt      \n",
            "  inflating: train/male/32.txt       \n",
            "  inflating: train/male/320.txt      \n",
            "  inflating: train/male/321.txt      \n",
            "  inflating: train/male/322.txt      \n",
            "  inflating: train/male/323.txt      \n",
            "  inflating: train/male/324.txt      \n",
            "  inflating: train/male/325.txt      \n",
            "  inflating: train/male/326.txt      \n",
            "  inflating: train/male/327.txt      \n",
            "  inflating: train/male/328.txt      \n",
            "  inflating: train/male/329.txt      \n",
            "  inflating: train/male/33.txt       \n",
            "  inflating: train/male/330.txt      \n",
            "  inflating: train/male/331.txt      \n",
            "  inflating: train/male/332.txt      \n",
            "  inflating: train/male/333.txt      \n",
            "  inflating: train/male/334.txt      \n",
            "  inflating: train/male/335.txt      \n",
            "  inflating: train/male/336.txt      \n",
            "  inflating: train/male/337.txt      \n",
            "  inflating: train/male/338.txt      \n",
            "  inflating: train/male/339.txt      \n",
            "  inflating: train/male/34.txt       \n",
            "  inflating: train/male/340.txt      \n",
            "  inflating: train/male/341.txt      \n",
            "  inflating: train/male/342.txt      \n",
            "  inflating: train/male/343.txt      \n",
            "  inflating: train/male/344.txt      \n",
            "  inflating: train/male/345.txt      \n",
            "  inflating: train/male/346.txt      \n",
            "  inflating: train/male/347.txt      \n",
            "  inflating: train/male/348.txt      \n",
            "  inflating: train/male/349.txt      \n",
            "  inflating: train/male/35.txt       \n",
            "  inflating: train/male/350.txt      \n",
            "  inflating: train/male/351.txt      \n",
            "  inflating: train/male/352.txt      \n",
            "  inflating: train/male/353.txt      \n",
            "  inflating: train/male/354.txt      \n",
            "  inflating: train/male/355.txt      \n",
            "  inflating: train/male/356.txt      \n",
            "  inflating: train/male/357.txt      \n",
            "  inflating: train/male/358.txt      \n",
            "  inflating: train/male/359.txt      \n",
            "  inflating: train/male/36.txt       \n",
            "  inflating: train/male/360.txt      \n",
            "  inflating: train/male/361.txt      \n",
            "  inflating: train/male/362.txt      \n",
            "  inflating: train/male/363.txt      \n",
            "  inflating: train/male/364.txt      \n",
            "  inflating: train/male/365.txt      \n",
            "  inflating: train/male/366.txt      \n",
            "  inflating: train/male/367.txt      \n",
            "  inflating: train/male/368.txt      \n",
            "  inflating: train/male/369.txt      \n",
            "  inflating: train/male/37.txt       \n",
            "  inflating: train/male/370.txt      \n",
            "  inflating: train/male/371.txt      \n",
            "  inflating: train/male/372.txt      \n",
            "  inflating: train/male/373.txt      \n",
            "  inflating: train/male/374.txt      \n",
            "  inflating: train/male/375.txt      \n",
            "  inflating: train/male/376.txt      \n",
            "  inflating: train/male/377.txt      \n",
            "  inflating: train/male/378.txt      \n",
            "  inflating: train/male/379.txt      \n",
            "  inflating: train/male/38.txt       \n",
            "  inflating: train/male/380.txt      \n",
            "  inflating: train/male/381.txt      \n",
            "  inflating: train/male/382.txt      \n",
            "  inflating: train/male/383.txt      \n",
            "  inflating: train/male/384.txt      \n",
            "  inflating: train/male/385.txt      \n",
            "  inflating: train/male/386.txt      \n",
            "  inflating: train/male/387.txt      \n",
            "  inflating: train/male/388.txt      \n",
            "  inflating: train/male/389.txt      \n",
            "  inflating: train/male/39.txt       \n",
            "  inflating: train/male/390.txt      \n",
            "  inflating: train/male/391.txt      \n",
            "  inflating: train/male/392.txt      \n",
            "  inflating: train/male/393.txt      \n",
            "  inflating: train/male/394.txt      \n",
            "  inflating: train/male/395.txt      \n",
            "  inflating: train/male/396.txt      \n",
            "  inflating: train/male/397.txt      \n",
            "  inflating: train/male/398.txt      \n",
            "  inflating: train/male/399.txt      \n",
            "  inflating: train/male/4.txt        \n",
            "  inflating: train/male/40.txt       \n",
            "  inflating: train/male/400.txt      \n",
            "  inflating: train/male/401.txt      \n",
            "  inflating: train/male/402.txt      \n",
            "  inflating: train/male/403.txt      \n",
            "  inflating: train/male/404.txt      \n",
            "  inflating: train/male/405.txt      \n",
            "  inflating: train/male/406.txt      \n",
            "  inflating: train/male/407.txt      \n",
            "  inflating: train/male/408.txt      \n",
            "  inflating: train/male/409.txt      \n",
            "  inflating: train/male/41.txt       \n",
            "  inflating: train/male/410.txt      \n",
            "  inflating: train/male/411.txt      \n",
            "  inflating: train/male/412.txt      \n",
            "  inflating: train/male/413.txt      \n",
            "  inflating: train/male/414.txt      \n",
            "  inflating: train/male/415.txt      \n",
            "  inflating: train/male/416.txt      \n",
            "  inflating: train/male/417.txt      \n",
            "  inflating: train/male/418.txt      \n",
            "  inflating: train/male/419.txt      \n",
            "  inflating: train/male/42.txt       \n",
            "  inflating: train/male/420.txt      \n",
            "  inflating: train/male/421.txt      \n",
            "  inflating: train/male/422.txt      \n",
            "  inflating: train/male/423.txt      \n",
            "  inflating: train/male/424.txt      \n",
            "  inflating: train/male/425.txt      \n",
            "  inflating: train/male/426.txt      \n",
            "  inflating: train/male/427.txt      \n",
            "  inflating: train/male/428.txt      \n",
            "  inflating: train/male/429.txt      \n",
            "  inflating: train/male/43.txt       \n",
            "  inflating: train/male/430.txt      \n",
            "  inflating: train/male/431.txt      \n",
            "  inflating: train/male/432.txt      \n",
            "  inflating: train/male/433.txt      \n",
            "  inflating: train/male/434.txt      \n",
            "  inflating: train/male/435.txt      \n",
            "  inflating: train/male/436.txt      \n",
            "  inflating: train/male/437.txt      \n",
            "  inflating: train/male/438.txt      \n",
            "  inflating: train/male/439.txt      \n",
            "  inflating: train/male/44.txt       \n",
            "  inflating: train/male/440.txt      \n",
            "  inflating: train/male/441.txt      \n",
            "  inflating: train/male/442.txt      \n",
            "  inflating: train/male/443.txt      \n",
            "  inflating: train/male/444.txt      \n",
            "  inflating: train/male/445.txt      \n",
            "  inflating: train/male/446.txt      \n",
            "  inflating: train/male/447.txt      \n",
            "  inflating: train/male/448.txt      \n",
            "  inflating: train/male/449.txt      \n",
            "  inflating: train/male/45.txt       \n",
            "  inflating: train/male/450.txt      \n",
            "  inflating: train/male/451.txt      \n",
            "  inflating: train/male/452.txt      \n",
            "  inflating: train/male/453.txt      \n",
            "  inflating: train/male/454.txt      \n",
            "  inflating: train/male/455.txt      \n",
            "  inflating: train/male/456.txt      \n",
            "  inflating: train/male/457.txt      \n",
            "  inflating: train/male/458.txt      \n",
            "  inflating: train/male/459.txt      \n",
            "  inflating: train/male/46.txt       \n",
            "  inflating: train/male/460.txt      \n",
            "  inflating: train/male/461.txt      \n",
            "  inflating: train/male/462.txt      \n",
            "  inflating: train/male/463.txt      \n",
            "  inflating: train/male/464.txt      \n",
            "  inflating: train/male/465.txt      \n",
            "  inflating: train/male/466.txt      \n",
            "  inflating: train/male/467.txt      \n",
            "  inflating: train/male/468.txt      \n",
            "  inflating: train/male/469.txt      \n",
            "  inflating: train/male/47.txt       \n",
            "  inflating: train/male/470.txt      \n",
            "  inflating: train/male/471.txt      \n",
            "  inflating: train/male/472.txt      \n",
            "  inflating: train/male/473.txt      \n",
            "  inflating: train/male/474.txt      \n",
            "  inflating: train/male/475.txt      \n",
            "  inflating: train/male/476.txt      \n",
            "  inflating: train/male/477.txt      \n",
            "  inflating: train/male/478.txt      \n",
            "  inflating: train/male/479.txt      \n",
            "  inflating: train/male/48.txt       \n",
            "  inflating: train/male/480.txt      \n",
            "  inflating: train/male/481.txt      \n",
            "  inflating: train/male/482.txt      \n",
            "  inflating: train/male/483.txt      \n",
            "  inflating: train/male/484.txt      \n",
            "  inflating: train/male/485.txt      \n",
            "  inflating: train/male/486.txt      \n",
            "  inflating: train/male/487.txt      \n",
            "  inflating: train/male/488.txt      \n",
            "  inflating: train/male/489.txt      \n",
            "  inflating: train/male/49.txt       \n",
            "  inflating: train/male/490.txt      \n",
            "  inflating: train/male/491.txt      \n",
            "  inflating: train/male/492.txt      \n",
            "  inflating: train/male/493.txt      \n",
            "  inflating: train/male/494.txt      \n",
            "  inflating: train/male/495.txt      \n",
            "  inflating: train/male/496.txt      \n",
            "  inflating: train/male/497.txt      \n",
            "  inflating: train/male/498.txt      \n",
            "  inflating: train/male/499.txt      \n",
            "  inflating: train/male/5.txt        \n",
            "  inflating: train/male/50.txt       \n",
            "  inflating: train/male/500.txt      \n",
            "  inflating: train/male/501.txt      \n",
            "  inflating: train/male/502.txt      \n",
            "  inflating: train/male/503.txt      \n",
            "  inflating: train/male/504.txt      \n",
            "  inflating: train/male/505.txt      \n",
            "  inflating: train/male/506.txt      \n",
            "  inflating: train/male/507.txt      \n",
            "  inflating: train/male/508.txt      \n",
            "  inflating: train/male/509.txt      \n",
            "  inflating: train/male/51.txt       \n",
            "  inflating: train/male/510.txt      \n",
            "  inflating: train/male/511.txt      \n",
            "  inflating: train/male/512.txt      \n",
            "  inflating: train/male/513.txt      \n",
            "  inflating: train/male/514.txt      \n",
            "  inflating: train/male/515.txt      \n",
            "  inflating: train/male/516.txt      \n",
            "  inflating: train/male/517.txt      \n",
            "  inflating: train/male/518.txt      \n",
            "  inflating: train/male/519.txt      \n",
            "  inflating: train/male/52.txt       \n",
            "  inflating: train/male/520.txt      \n",
            "  inflating: train/male/521.txt      \n",
            "  inflating: train/male/522.txt      \n",
            "  inflating: train/male/523.txt      \n",
            "  inflating: train/male/524.txt      \n",
            "  inflating: train/male/525.txt      \n",
            "  inflating: train/male/526.txt      \n",
            "  inflating: train/male/527.txt      \n",
            "  inflating: train/male/528.txt      \n",
            "  inflating: train/male/529.txt      \n",
            "  inflating: train/male/53.txt       \n",
            "  inflating: train/male/530.txt      \n",
            "  inflating: train/male/531.txt      \n",
            "  inflating: train/male/532.txt      \n",
            "  inflating: train/male/533.txt      \n",
            "  inflating: train/male/534.txt      \n",
            "  inflating: train/male/535.txt      \n",
            "  inflating: train/male/536.txt      \n",
            "  inflating: train/male/537.txt      \n",
            "  inflating: train/male/538.txt      \n",
            "  inflating: train/male/539.txt      \n",
            "  inflating: train/male/54.txt       \n",
            "  inflating: train/male/540.txt      \n",
            "  inflating: train/male/541.txt      \n",
            "  inflating: train/male/542.txt      \n",
            "  inflating: train/male/543.txt      \n",
            "  inflating: train/male/544.txt      \n",
            "  inflating: train/male/545.txt      \n",
            "  inflating: train/male/546.txt      \n",
            "  inflating: train/male/547.txt      \n",
            "  inflating: train/male/548.txt      \n",
            "  inflating: train/male/549.txt      \n",
            "  inflating: train/male/55.txt       \n",
            "  inflating: train/male/550.txt      \n",
            "  inflating: train/male/551.txt      \n",
            "  inflating: train/male/552.txt      \n",
            "  inflating: train/male/553.txt      \n",
            "  inflating: train/male/554.txt      \n",
            "  inflating: train/male/555.txt      \n",
            "  inflating: train/male/556.txt      \n",
            "  inflating: train/male/557.txt      \n",
            "  inflating: train/male/558.txt      \n",
            "  inflating: train/male/559.txt      \n",
            "  inflating: train/male/56.txt       \n",
            "  inflating: train/male/560.txt      \n",
            "  inflating: train/male/561.txt      \n",
            "  inflating: train/male/562.txt      \n",
            "  inflating: train/male/563.txt      \n",
            "  inflating: train/male/564.txt      \n",
            "  inflating: train/male/565.txt      \n",
            "  inflating: train/male/566.txt      \n",
            "  inflating: train/male/567.txt      \n",
            "  inflating: train/male/568.txt      \n",
            "  inflating: train/male/569.txt      \n",
            "  inflating: train/male/57.txt       \n",
            "  inflating: train/male/570.txt      \n",
            "  inflating: train/male/571.txt      \n",
            "  inflating: train/male/572.txt      \n",
            "  inflating: train/male/573.txt      \n",
            "  inflating: train/male/574.txt      \n",
            "  inflating: train/male/575.txt      \n",
            "  inflating: train/male/576.txt      \n",
            "  inflating: train/male/577.txt      \n",
            "  inflating: train/male/578.txt      \n",
            "  inflating: train/male/579.txt      \n",
            "  inflating: train/male/58.txt       \n",
            "  inflating: train/male/580.txt      \n",
            "  inflating: train/male/581.txt      \n",
            "  inflating: train/male/582.txt      \n",
            "  inflating: train/male/583.txt      \n",
            "  inflating: train/male/584.txt      \n",
            "  inflating: train/male/585.txt      \n",
            "  inflating: train/male/586.txt      \n",
            "  inflating: train/male/587.txt      \n",
            "  inflating: train/male/588.txt      \n",
            "  inflating: train/male/589.txt      \n",
            "  inflating: train/male/59.txt       \n",
            "  inflating: train/male/590.txt      \n",
            "  inflating: train/male/591.txt      \n",
            "  inflating: train/male/592.txt      \n",
            "  inflating: train/male/593.txt      \n",
            "  inflating: train/male/594.txt      \n",
            "  inflating: train/male/595.txt      \n",
            "  inflating: train/male/596.txt      \n",
            "  inflating: train/male/597.txt      \n",
            "  inflating: train/male/598.txt      \n",
            "  inflating: train/male/599.txt      \n",
            "  inflating: train/male/6.txt        \n",
            "  inflating: train/male/60.txt       \n",
            "  inflating: train/male/600.txt      \n",
            "  inflating: train/male/601.txt      \n",
            "  inflating: train/male/602.txt      \n",
            "  inflating: train/male/603.txt      \n",
            "  inflating: train/male/604.txt      \n",
            "  inflating: train/male/605.txt      \n",
            "  inflating: train/male/606.txt      \n",
            "  inflating: train/male/607.txt      \n",
            "  inflating: train/male/608.txt      \n",
            "  inflating: train/male/609.txt      \n",
            "  inflating: train/male/61.txt       \n",
            "  inflating: train/male/610.txt      \n",
            "  inflating: train/male/611.txt      \n",
            "  inflating: train/male/612.txt      \n",
            "  inflating: train/male/613.txt      \n",
            "  inflating: train/male/614.txt      \n",
            "  inflating: train/male/615.txt      \n",
            "  inflating: train/male/616.txt      \n",
            "  inflating: train/male/617.txt      \n",
            "  inflating: train/male/618.txt      \n",
            "  inflating: train/male/619.txt      \n",
            "  inflating: train/male/62.txt       \n",
            "  inflating: train/male/620.txt      \n",
            "  inflating: train/male/621.txt      \n",
            "  inflating: train/male/622.txt      \n",
            "  inflating: train/male/623.txt      \n",
            "  inflating: train/male/624.txt      \n",
            "  inflating: train/male/625.txt      \n",
            "  inflating: train/male/626.txt      \n",
            "  inflating: train/male/627.txt      \n",
            "  inflating: train/male/628.txt      \n",
            "  inflating: train/male/629.txt      \n",
            "  inflating: train/male/63.txt       \n",
            "  inflating: train/male/630.txt      \n",
            "  inflating: train/male/631.txt      \n",
            "  inflating: train/male/632.txt      \n",
            "  inflating: train/male/633.txt      \n",
            "  inflating: train/male/634.txt      \n",
            "  inflating: train/male/635.txt      \n",
            "  inflating: train/male/636.txt      \n",
            "  inflating: train/male/637.txt      \n",
            "  inflating: train/male/638.txt      \n",
            "  inflating: train/male/639.txt      \n",
            "  inflating: train/male/64.txt       \n",
            "  inflating: train/male/640.txt      \n",
            "  inflating: train/male/641.txt      \n",
            "  inflating: train/male/642.txt      \n",
            "  inflating: train/male/643.txt      \n",
            "  inflating: train/male/644.txt      \n",
            "  inflating: train/male/645.txt      \n",
            "  inflating: train/male/646.txt      \n",
            "  inflating: train/male/647.txt      \n",
            "  inflating: train/male/648.txt      \n",
            "  inflating: train/male/649.txt      \n",
            "  inflating: train/male/65.txt       \n",
            "  inflating: train/male/650.txt      \n",
            "  inflating: train/male/651.txt      \n",
            "  inflating: train/male/652.txt      \n",
            "  inflating: train/male/653.txt      \n",
            "  inflating: train/male/654.txt      \n",
            "  inflating: train/male/655.txt      \n",
            "  inflating: train/male/656.txt      \n",
            "  inflating: train/male/657.txt      \n",
            "  inflating: train/male/658.txt      \n",
            "  inflating: train/male/659.txt      \n",
            "  inflating: train/male/66.txt       \n",
            "  inflating: train/male/660.txt      \n",
            "  inflating: train/male/661.txt      \n",
            "  inflating: train/male/662.txt      \n",
            "  inflating: train/male/663.txt      \n",
            "  inflating: train/male/664.txt      \n",
            "  inflating: train/male/665.txt      \n",
            "  inflating: train/male/666.txt      \n",
            "  inflating: train/male/667.txt      \n",
            "  inflating: train/male/668.txt      \n",
            "  inflating: train/male/669.txt      \n",
            "  inflating: train/male/67.txt       \n",
            "  inflating: train/male/670.txt      \n",
            "  inflating: train/male/671.txt      \n",
            "  inflating: train/male/672.txt      \n",
            "  inflating: train/male/673.txt      \n",
            "  inflating: train/male/674.txt      \n",
            "  inflating: train/male/675.txt      \n",
            "  inflating: train/male/676.txt      \n",
            "  inflating: train/male/677.txt      \n",
            "  inflating: train/male/678.txt      \n",
            "  inflating: train/male/679.txt      \n",
            "  inflating: train/male/68.txt       \n",
            "  inflating: train/male/680.txt      \n",
            "  inflating: train/male/681.txt      \n",
            "  inflating: train/male/682.txt      \n",
            "  inflating: train/male/683.txt      \n",
            "  inflating: train/male/684.txt      \n",
            "  inflating: train/male/685.txt      \n",
            "  inflating: train/male/686.txt      \n",
            "  inflating: train/male/687.txt      \n",
            "  inflating: train/male/688.txt      \n",
            "  inflating: train/male/689.txt      \n",
            "  inflating: train/male/69.txt       \n",
            "  inflating: train/male/690.txt      \n",
            "  inflating: train/male/691.txt      \n",
            "  inflating: train/male/692.txt      \n",
            "  inflating: train/male/693.txt      \n",
            "  inflating: train/male/694.txt      \n",
            "  inflating: train/male/695.txt      \n",
            "  inflating: train/male/696.txt      \n",
            "  inflating: train/male/697.txt      \n",
            "  inflating: train/male/698.txt      \n",
            "  inflating: train/male/699.txt      \n",
            "  inflating: train/male/7.txt        \n",
            "  inflating: train/male/70.txt       \n",
            "  inflating: train/male/700.txt      \n",
            "  inflating: train/male/701.txt      \n",
            "  inflating: train/male/702.txt      \n",
            "  inflating: train/male/703.txt      \n",
            "  inflating: train/male/704.txt      \n",
            "  inflating: train/male/705.txt      \n",
            "  inflating: train/male/706.txt      \n",
            "  inflating: train/male/707.txt      \n",
            "  inflating: train/male/708.txt      \n",
            "  inflating: train/male/709.txt      \n",
            "  inflating: train/male/71.txt       \n",
            "  inflating: train/male/710.txt      \n",
            "  inflating: train/male/711.txt      \n",
            "  inflating: train/male/712.txt      \n",
            "  inflating: train/male/713.txt      \n",
            "  inflating: train/male/714.txt      \n",
            "  inflating: train/male/715.txt      \n",
            "  inflating: train/male/716.txt      \n",
            "  inflating: train/male/717.txt      \n",
            "  inflating: train/male/718.txt      \n",
            "  inflating: train/male/719.txt      \n",
            "  inflating: train/male/72.txt       \n",
            "  inflating: train/male/720.txt      \n",
            "  inflating: train/male/721.txt      \n",
            "  inflating: train/male/722.txt      \n",
            "  inflating: train/male/723.txt      \n",
            "  inflating: train/male/724.txt      \n",
            "  inflating: train/male/725.txt      \n",
            "  inflating: train/male/726.txt      \n",
            "  inflating: train/male/727.txt      \n",
            "  inflating: train/male/728.txt      \n",
            "  inflating: train/male/729.txt      \n",
            "  inflating: train/male/73.txt       \n",
            "  inflating: train/male/730.txt      \n",
            "  inflating: train/male/731.txt      \n",
            "  inflating: train/male/732.txt      \n",
            "  inflating: train/male/733.txt      \n",
            "  inflating: train/male/734.txt      \n",
            "  inflating: train/male/735.txt      \n",
            "  inflating: train/male/736.txt      \n",
            "  inflating: train/male/737.txt      \n",
            "  inflating: train/male/738.txt      \n",
            "  inflating: train/male/739.txt      \n",
            "  inflating: train/male/74.txt       \n",
            "  inflating: train/male/740.txt      \n",
            "  inflating: train/male/741.txt      \n",
            "  inflating: train/male/742.txt      \n",
            "  inflating: train/male/743.txt      \n",
            "  inflating: train/male/744.txt      \n",
            "  inflating: train/male/745.txt      \n",
            "  inflating: train/male/746.txt      \n",
            "  inflating: train/male/747.txt      \n",
            "  inflating: train/male/748.txt      \n",
            "  inflating: train/male/749.txt      \n",
            "  inflating: train/male/75.txt       \n",
            "  inflating: train/male/750.txt      \n",
            "  inflating: train/male/751.txt      \n",
            "  inflating: train/male/752.txt      \n",
            "  inflating: train/male/753.txt      \n",
            "  inflating: train/male/754.txt      \n",
            "  inflating: train/male/755.txt      \n",
            "  inflating: train/male/756.txt      \n",
            "  inflating: train/male/757.txt      \n",
            "  inflating: train/male/758.txt      \n",
            "  inflating: train/male/759.txt      \n",
            "  inflating: train/male/76.txt       \n",
            "  inflating: train/male/760.txt      \n",
            "  inflating: train/male/761.txt      \n",
            "  inflating: train/male/762.txt      \n",
            "  inflating: train/male/763.txt      \n",
            "  inflating: train/male/764.txt      \n",
            "  inflating: train/male/765.txt      \n",
            "  inflating: train/male/766.txt      \n",
            "  inflating: train/male/767.txt      \n",
            "  inflating: train/male/768.txt      \n",
            "  inflating: train/male/769.txt      \n",
            "  inflating: train/male/77.txt       \n",
            "  inflating: train/male/770.txt      \n",
            "  inflating: train/male/771.txt      \n",
            "  inflating: train/male/772.txt      \n",
            "  inflating: train/male/773.txt      \n",
            "  inflating: train/male/774.txt      \n",
            "  inflating: train/male/775.txt      \n",
            "  inflating: train/male/776.txt      \n",
            "  inflating: train/male/777.txt      \n",
            "  inflating: train/male/778.txt      \n",
            "  inflating: train/male/779.txt      \n",
            "  inflating: train/male/78.txt       \n",
            "  inflating: train/male/780.txt      \n",
            "  inflating: train/male/781.txt      \n",
            "  inflating: train/male/782.txt      \n",
            "  inflating: train/male/783.txt      \n",
            "  inflating: train/male/784.txt      \n",
            "  inflating: train/male/785.txt      \n",
            "  inflating: train/male/786.txt      \n",
            "  inflating: train/male/787.txt      \n",
            "  inflating: train/male/788.txt      \n",
            "  inflating: train/male/789.txt      \n",
            "  inflating: train/male/79.txt       \n",
            "  inflating: train/male/790.txt      \n",
            "  inflating: train/male/791.txt      \n",
            "  inflating: train/male/792.txt      \n",
            "  inflating: train/male/793.txt      \n",
            "  inflating: train/male/794.txt      \n",
            "  inflating: train/male/795.txt      \n",
            "  inflating: train/male/796.txt      \n",
            "  inflating: train/male/797.txt      \n",
            "  inflating: train/male/798.txt      \n",
            "  inflating: train/male/799.txt      \n",
            "  inflating: train/male/8.txt        \n",
            "  inflating: train/male/80.txt       \n",
            "  inflating: train/male/800.txt      \n",
            "  inflating: train/male/801.txt      \n",
            "  inflating: train/male/802.txt      \n",
            "  inflating: train/male/803.txt      \n",
            "  inflating: train/male/804.txt      \n",
            "  inflating: train/male/805.txt      \n",
            "  inflating: train/male/806.txt      \n",
            "  inflating: train/male/807.txt      \n",
            "  inflating: train/male/808.txt      \n",
            "  inflating: train/male/809.txt      \n",
            "  inflating: train/male/81.txt       \n",
            "  inflating: train/male/810.txt      \n",
            "  inflating: train/male/811.txt      \n",
            "  inflating: train/male/812.txt      \n",
            "  inflating: train/male/813.txt      \n",
            "  inflating: train/male/814.txt      \n",
            "  inflating: train/male/815.txt      \n",
            "  inflating: train/male/816.txt      \n",
            "  inflating: train/male/817.txt      \n",
            "  inflating: train/male/818.txt      \n",
            "  inflating: train/male/819.txt      \n",
            "  inflating: train/male/82.txt       \n",
            "  inflating: train/male/820.txt      \n",
            "  inflating: train/male/821.txt      \n",
            "  inflating: train/male/822.txt      \n",
            "  inflating: train/male/823.txt      \n",
            "  inflating: train/male/824.txt      \n",
            "  inflating: train/male/825.txt      \n",
            "  inflating: train/male/826.txt      \n",
            "  inflating: train/male/827.txt      \n",
            "  inflating: train/male/828.txt      \n",
            "  inflating: train/male/829.txt      \n",
            "  inflating: train/male/83.txt       \n",
            "  inflating: train/male/830.txt      \n",
            "  inflating: train/male/831.txt      \n",
            "  inflating: train/male/832.txt      \n",
            "  inflating: train/male/833.txt      \n",
            "  inflating: train/male/834.txt      \n",
            "  inflating: train/male/835.txt      \n",
            "  inflating: train/male/836.txt      \n",
            "  inflating: train/male/837.txt      \n",
            "  inflating: train/male/838.txt      \n",
            "  inflating: train/male/839.txt      \n",
            "  inflating: train/male/84.txt       \n",
            "  inflating: train/male/840.txt      \n",
            "  inflating: train/male/841.txt      \n",
            "  inflating: train/male/842.txt      \n",
            "  inflating: train/male/843.txt      \n",
            "  inflating: train/male/844.txt      \n",
            "  inflating: train/male/845.txt      \n",
            "  inflating: train/male/846.txt      \n",
            "  inflating: train/male/847.txt      \n",
            "  inflating: train/male/848.txt      \n",
            "  inflating: train/male/849.txt      \n",
            "  inflating: train/male/85.txt       \n",
            "  inflating: train/male/850.txt      \n",
            "  inflating: train/male/851.txt      \n",
            "  inflating: train/male/852.txt      \n",
            "  inflating: train/male/853.txt      \n",
            "  inflating: train/male/854.txt      \n",
            "  inflating: train/male/855.txt      \n",
            "  inflating: train/male/856.txt      \n",
            "  inflating: train/male/857.txt      \n",
            "  inflating: train/male/858.txt      \n",
            "  inflating: train/male/859.txt      \n",
            "  inflating: train/male/86.txt       \n",
            "  inflating: train/male/860.txt      \n",
            "  inflating: train/male/861.txt      \n",
            "  inflating: train/male/862.txt      \n",
            "  inflating: train/male/863.txt      \n",
            "  inflating: train/male/864.txt      \n",
            "  inflating: train/male/865.txt      \n",
            "  inflating: train/male/866.txt      \n",
            "  inflating: train/male/867.txt      \n",
            "  inflating: train/male/868.txt      \n",
            "  inflating: train/male/869.txt      \n",
            "  inflating: train/male/87.txt       \n",
            "  inflating: train/male/870.txt      \n",
            "  inflating: train/male/871.txt      \n",
            "  inflating: train/male/872.txt      \n",
            "  inflating: train/male/873.txt      \n",
            "  inflating: train/male/874.txt      \n",
            "  inflating: train/male/875.txt      \n",
            "  inflating: train/male/876.txt      \n",
            "  inflating: train/male/877.txt      \n",
            "  inflating: train/male/878.txt      \n",
            "  inflating: train/male/879.txt      \n",
            "  inflating: train/male/88.txt       \n",
            "  inflating: train/male/880.txt      \n",
            "  inflating: train/male/881.txt      \n",
            "  inflating: train/male/882.txt      \n",
            "  inflating: train/male/883.txt      \n",
            "  inflating: train/male/884.txt      \n",
            "  inflating: train/male/885.txt      \n",
            "  inflating: train/male/886.txt      \n",
            "  inflating: train/male/887.txt      \n",
            "  inflating: train/male/888.txt      \n",
            "  inflating: train/male/889.txt      \n",
            "  inflating: train/male/89.txt       \n",
            "  inflating: train/male/890.txt      \n",
            "  inflating: train/male/891.txt      \n",
            "  inflating: train/male/892.txt      \n",
            "  inflating: train/male/893.txt      \n",
            "  inflating: train/male/894.txt      \n",
            "  inflating: train/male/895.txt      \n",
            "  inflating: train/male/896.txt      \n",
            "  inflating: train/male/897.txt      \n",
            "  inflating: train/male/898.txt      \n",
            "  inflating: train/male/899.txt      \n",
            "  inflating: train/male/9.txt        \n",
            "  inflating: train/male/90.txt       \n",
            "  inflating: train/male/900.txt      \n",
            "  inflating: train/male/901.txt      \n",
            "  inflating: train/male/902.txt      \n",
            "  inflating: train/male/903.txt      \n",
            "  inflating: train/male/904.txt      \n",
            "  inflating: train/male/905.txt      \n",
            "  inflating: train/male/906.txt      \n",
            "  inflating: train/male/907.txt      \n",
            "  inflating: train/male/908.txt      \n",
            "  inflating: train/male/909.txt      \n",
            "  inflating: train/male/91.txt       \n",
            "  inflating: train/male/910.txt      \n",
            "  inflating: train/male/911.txt      \n",
            "  inflating: train/male/912.txt      \n",
            "  inflating: train/male/913.txt      \n",
            "  inflating: train/male/914.txt      \n",
            "  inflating: train/male/915.txt      \n",
            "  inflating: train/male/916.txt      \n",
            "  inflating: train/male/917.txt      \n",
            "  inflating: train/male/918.txt      \n",
            "  inflating: train/male/919.txt      \n",
            "  inflating: train/male/92.txt       \n",
            "  inflating: train/male/920.txt      \n",
            "  inflating: train/male/921.txt      \n",
            "  inflating: train/male/922.txt      \n",
            "  inflating: train/male/923.txt      \n",
            "  inflating: train/male/924.txt      \n",
            "  inflating: train/male/925.txt      \n",
            "  inflating: train/male/926.txt      \n",
            "  inflating: train/male/927.txt      \n",
            "  inflating: train/male/928.txt      \n",
            "  inflating: train/male/929.txt      \n",
            "  inflating: train/male/93.txt       \n",
            "  inflating: train/male/930.txt      \n",
            "  inflating: train/male/931.txt      \n",
            "  inflating: train/male/932.txt      \n",
            "  inflating: train/male/933.txt      \n",
            "  inflating: train/male/934.txt      \n",
            "  inflating: train/male/935.txt      \n",
            "  inflating: train/male/936.txt      \n",
            "  inflating: train/male/937.txt      \n",
            "  inflating: train/male/938.txt      \n",
            "  inflating: train/male/939.txt      \n",
            "  inflating: train/male/94.txt       \n",
            "  inflating: train/male/940.txt      \n",
            "  inflating: train/male/941.txt      \n",
            "  inflating: train/male/942.txt      \n",
            "  inflating: train/male/943.txt      \n",
            "  inflating: train/male/944.txt      \n",
            "  inflating: train/male/945.txt      \n",
            "  inflating: train/male/946.txt      \n",
            "  inflating: train/male/947.txt      \n",
            "  inflating: train/male/948.txt      \n",
            "  inflating: train/male/949.txt      \n",
            "  inflating: train/male/95.txt       \n",
            "  inflating: train/male/950.txt      \n",
            "  inflating: train/male/951.txt      \n",
            "  inflating: train/male/952.txt      \n",
            "  inflating: train/male/953.txt      \n",
            "  inflating: train/male/954.txt      \n",
            "  inflating: train/male/955.txt      \n",
            "  inflating: train/male/956.txt      \n",
            "  inflating: train/male/957.txt      \n",
            "  inflating: train/male/958.txt      \n",
            "  inflating: train/male/959.txt      \n",
            "  inflating: train/male/96.txt       \n",
            "  inflating: train/male/960.txt      \n",
            "  inflating: train/male/961.txt      \n",
            "  inflating: train/male/962.txt      \n",
            "  inflating: train/male/963.txt      \n",
            "  inflating: train/male/964.txt      \n",
            "  inflating: train/male/965.txt      \n",
            "  inflating: train/male/966.txt      \n",
            "  inflating: train/male/967.txt      \n",
            "  inflating: train/male/968.txt      \n",
            "  inflating: train/male/969.txt      \n",
            "  inflating: train/male/97.txt       \n",
            "  inflating: train/male/970.txt      \n",
            "  inflating: train/male/971.txt      \n",
            "  inflating: train/male/972.txt      \n",
            "  inflating: train/male/973.txt      \n",
            "  inflating: train/male/974.txt      \n",
            "  inflating: train/male/975.txt      \n",
            "  inflating: train/male/976.txt      \n",
            "  inflating: train/male/977.txt      \n",
            "  inflating: train/male/978.txt      \n",
            "  inflating: train/male/979.txt      \n",
            "  inflating: train/male/98.txt       \n",
            "  inflating: train/male/980.txt      \n",
            "  inflating: train/male/981.txt      \n",
            "  inflating: train/male/982.txt      \n",
            "  inflating: train/male/983.txt      \n",
            "  inflating: train/male/984.txt      \n",
            "  inflating: train/male/985.txt      \n",
            "  inflating: train/male/986.txt      \n",
            "  inflating: train/male/987.txt      \n",
            "  inflating: train/male/988.txt      \n",
            "  inflating: train/male/989.txt      \n",
            "  inflating: train/male/99.txt       \n",
            "  inflating: train/male/990.txt      \n",
            "  inflating: train/male/991.txt      \n",
            "  inflating: train/male/992.txt      \n",
            "  inflating: train/male/993.txt      \n",
            "  inflating: train/male/994.txt      \n",
            "  inflating: train/male/995.txt      \n",
            "  inflating: train/male/996.txt      \n",
            "  inflating: train/male/997.txt      \n",
            "  inflating: train/male/998.txt      \n",
            "  inflating: train/male/999.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG7J-NKBITvv",
        "outputId": "84fde388-4b2e-4d2d-f4ec-54a92e0c6024"
      },
      "source": [
        "!pip install hazm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\r\u001b[K     |█                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 7.7MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 26.9MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.15.0)\n",
            "Building wheels for collected packages: libwapiti, nltk\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154994 sha256=b9223ffc9e833cc6f2b4e3baf313f5dd6f455687692cd341ef2015bdba1b6871\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394472 sha256=e90e39e86f424fc67005ae315f47ca59bbd4082479068b5d08e9dd6530db6991\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built libwapiti nltk\n",
            "Installing collected packages: libwapiti, nltk, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCR0nukymgXm",
        "outputId": "e65b1d36-5deb-43f0-8407-848b16ca16f8"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=7278a470c0cd79aba3ad0481ab3a7b93d43324f6fb56d57c31dfb5841f0d7580\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HFgKBqOwZXj",
        "outputId": "7e009f70-91ae-4c2e-9eda-cb974d5c3ba5"
      },
      "source": [
        "!wget -nc https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-02 15:46:30--  https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/13956112/8c6c89ce-1918-11e5-9f06-86f58ea50386?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210402%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210402T154630Z&X-Amz-Expires=300&X-Amz-Signature=52d0612ec8f18cafefc383286937dadd00dd34b51d5baf0b8f76dd1c64f3022e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=13956112&response-content-disposition=attachment%3B%20filename%3Dresources-0.5.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-02 15:46:30--  https://github-releases.githubusercontent.com/13956112/8c6c89ce-1918-11e5-9f06-86f58ea50386?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210402%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210402T154630Z&X-Amz-Expires=300&X-Amz-Signature=52d0612ec8f18cafefc383286937dadd00dd34b51d5baf0b8f76dd1c64f3022e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=13956112&response-content-disposition=attachment%3B%20filename%3Dresources-0.5.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.110.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30557783 (29M) [application/octet-stream]\n",
            "Saving to: ‘resources-0.5.zip’\n",
            "\n",
            "resources-0.5.zip   100%[===================>]  29.14M  38.5MB/s    in 0.8s    \n",
            "\n",
            "2021-04-02 15:46:32 (38.5 MB/s) - ‘resources-0.5.zip’ saved [30557783/30557783]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbadtPNOwjeB",
        "outputId": "f06ee480-368e-494c-a40a-e288de5a111f"
      },
      "source": [
        "!unzip -o /content/resources-0.5.zip -d /content/resources/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/resources-0.5.zip\n",
            "  inflating: /content/resources/chunker.model  \n",
            "  inflating: /content/resources/langModel.mco  \n",
            "   creating: /content/resources/lib/\n",
            "  inflating: /content/resources/lib/liblinear-1.8.jar  \n",
            "  inflating: /content/resources/lib/libsvm.jar  \n",
            "  inflating: /content/resources/lib/log4j.jar  \n",
            "  inflating: /content/resources/malt.jar  \n",
            "  inflating: /content/resources/postagger.model  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKX1TX7MakoR"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hazm import Normalizer, Stemmer, Lemmatizer, word_tokenize, POSTagger\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from scipy.spatial.distance import pdist, cdist\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfhT7EB1RkMI"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6McOMUeyfxIj",
        "outputId": "c35a83fd-63ee-4eb0-9ade-796e28b9db1e"
      },
      "source": [
        "data = []\n",
        "\n",
        "def read_files(path, tag):\n",
        "  for file in os.listdir(path):\n",
        "      with open(f\"{path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "        data.append([f.read().strip(), tag])\n",
        "\n",
        "read_files(\"/content/train/female\", \"female\")\n",
        "read_files(\"/content/train/male\", \"male\")\n",
        "\n",
        "dataset = pd.DataFrame(data, columns = [\"Comment\", \"Gender\"]) \n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>من میخواستم برم کیش موندم کدام هتل را برم ولی ...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من در مرداد ماه به همراه خواهرم و پسرش و دخترم...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>وای از سرو صدا</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>سلام من به همراه همسرم و مادر و برادر همسرم در...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  Gender\n",
              "0     اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...  female\n",
              "1     سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...  female\n",
              "2     من میخواستم برم کیش موندم کدام هتل را برم ولی ...  female\n",
              "3     من در مرداد ماه به همراه خواهرم و پسرش و دخترم...  female\n",
              "4     سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...  female\n",
              "...                                                 ...     ...\n",
              "1995  سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...    male\n",
              "1996  بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...    male\n",
              "1997  با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...    male\n",
              "1998                                     وای از سرو صدا    male\n",
              "1999  سلام من به همراه همسرم و مادر و برادر همسرم در...    male\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xajwWQGUDBx5"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTcL-k9X212_"
      },
      "source": [
        "Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsz3CyBt2x7i"
      },
      "source": [
        "class MonitorCallback(CallbackAny2Vec):\n",
        "    def __init__(self, test_words):\n",
        "        self._test_words = test_words\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        #clear_output(wait=True)\n",
        "        print(\"Model loss:\", model.get_latest_training_loss())  # print loss\n",
        "        for word in self._test_words:  # show wv logic changes\n",
        "            print(model.wv.most_similar(word))\n",
        "            \n",
        "def train_w2v_model(input_sentences): \n",
        "    #model = Word2Vec(sentences=input_sentences, size=100, window=8, min_count=1, workers=4)\n",
        "    monitor = MonitorCallback([\"هتل\"])  # monitor with demo words\n",
        "    # creating an object 'model' of Word2Vec and building vocabulary for training our model\n",
        "    model = Word2Vec(size=100, window=8, min_count=1, workers=4, callbacks=[monitor])\n",
        "    # building vocabulary for training\n",
        "    model.build_vocab(input_sentences)\n",
        "    print(\"\\n Training the word2vec model...\\n\")\n",
        "    # reducing the epochs will decrease the computation time\n",
        "    model.train(input_sentences, total_examples=len(input_sentences), epochs=50)\n",
        "    model.save('/content/the_model.w2v')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0u_PW-INLql"
      },
      "source": [
        "normalizer = Normalizer()\n",
        "stemmer = Stemmer()\n",
        "lemmatizer = Lemmatizer()\n",
        "stop_words = []\n",
        "model = Word2Vec.load('/content/NLP-Assignments/the_model acc=62.7 s=100 win=8 epc=50.w2v')\n",
        "file = open('/content/NLP-Assignments/stop words.txt', 'r')\n",
        "for line in file.readlines():\n",
        "    stop_words.append(line.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysrgCxgGDFS8"
      },
      "source": [
        "def preprocess(row):\n",
        "    \n",
        "    text = row['Comment']\n",
        "\n",
        "    #Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    #Remove punctuations\n",
        "    text = re.sub('['+string.punctuation+']', ' ', text)\n",
        "\n",
        "    #Normalization\n",
        "    text = normalizer.normalize(text)\n",
        "    \n",
        "    #Tokenization\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    #Tokenization\n",
        "    raw_words = word_tokenize(row['Comment'])\n",
        "\n",
        "    #Remove OOV\n",
        "    w2v = [word for word in raw_words if word in model]\n",
        "\n",
        "    #Remove stop words\n",
        "    words = [word for word in words if not word in stop_words]\n",
        "\n",
        "    #Stemming\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    #Lemmatization\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    \n",
        "    text = ' '.join(words)\n",
        "\n",
        "    return {'Comment':row['Comment'], 'Text':text, 'Words':w2v, 'Gender':row['Gender']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "hb1Vlu0yDJ2N",
        "outputId": "5917e8bb-d56d-46d5-d503-c928807a547e"
      },
      "source": [
        "df = pd.DataFrame(list(dataset.apply(preprocess, axis=1)))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Words</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...</td>\n",
              "      <td>اتاق کثیف پرسنل برخورد خوب داشت#دار خوب نزدیک ...</td>\n",
              "      <td>[اتاقها, کثیف, بود, ., پرسنل, برخورد, خوبی, ند...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...</td>\n",
              "      <td>سلا ببخشید می‌خواس بدون ایا عاد پول اینجا چقدر...</td>\n",
              "      <td>[سلام, ببخشید, می, خواستم, بدونم, در, ایام, عا...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>من میخواستم برم کیش موندم کدام هتل را برم ولی ...</td>\n",
              "      <td>میخواس بر ک موند هتل بر تواین سا دید هتل مر تع...</td>\n",
              "      <td>[من, میخواستم, برم, کیش, موندم, کدام, هتل, را,...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من در مرداد ماه به همراه خواهرم و پسرش و دخترم...</td>\n",
              "      <td>مرداد ماه همراه خواهر پسر دختر درهتل بود#باش ص...</td>\n",
              "      <td>[من, در, مرداد, ماه, به, همراه, خواهرم, و, پسر...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...</td>\n",
              "      <td>سلا دیروز ک اومد رفتن این نظر خوند برگ ندا نظر...</td>\n",
              "      <td>[سلام, ., من, دیروز, از, کیش, اومدم, ., قبل, ر...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...</td>\n",
              "      <td>سلا دوس ک برگ هتل آنا رو برا اقام انتخاب کرد#ک...</td>\n",
              "      <td>[سلام, من, با, دوستم, تازه, از, کیش, برگشتیم, ...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...</td>\n",
              "      <td>بخ هتل نوساز شیک تره بخ ویلا خوبه ظاهرا اتاق ب...</td>\n",
              "      <td>[بخش, هتلی, نوسازتر, و, شیک, تره, ., اما, بخش,...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...</td>\n",
              "      <td>سلا سال هفته اسفند ذر این هتل اقام دا هتل نسب ...</td>\n",
              "      <td>[با, سلام, من, سال, پیش, هفته, دوم, اسفند, ذر,...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>وای از سرو صدا</td>\n",
              "      <td>وا سرو صدا</td>\n",
              "      <td>[وای, از, سرو, صدا]</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>سلام من به همراه همسرم و مادر و برادر همسرم در...</td>\n",
              "      <td>سلا همراه همسر مادر برادر همسر این هتل زیبا اق...</td>\n",
              "      <td>[سلام, من, به, همراه, همسرم, و, مادر, و, برادر...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  ...  Gender\n",
              "0     اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...  ...  female\n",
              "1     سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...  ...  female\n",
              "2     من میخواستم برم کیش موندم کدام هتل را برم ولی ...  ...  female\n",
              "3     من در مرداد ماه به همراه خواهرم و پسرش و دخترم...  ...  female\n",
              "4     سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...  ...  female\n",
              "...                                                 ...  ...     ...\n",
              "1995  سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...  ...    male\n",
              "1996  بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...  ...    male\n",
              "1997  با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...  ...    male\n",
              "1998                                     وای از سرو صدا  ...    male\n",
              "1999  سلام من به همراه همسرم و مادر و برادر همسرم در...  ...    male\n",
              "\n",
              "[2000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnIgrkYfBCAN"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX5oaXiEe2b0"
      },
      "source": [
        "# returns (the number of words in the str which repeated n times) / (total number of words)\n",
        "# hapax_legomena_ratio\n",
        "def word_frequency(str,n):\n",
        "    counts = dict()\n",
        "    words = str.split()\n",
        " \n",
        "    for word in words:\n",
        "        if word in counts:\n",
        "            counts[word] += 1\n",
        "        else:\n",
        "            counts[word] = 1\n",
        " \n",
        "    return list(counts.values()).count(n)/len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aotCmVvOk5Ol"
      },
      "source": [
        "# yule's K measure\n",
        "def yulesk(str):\n",
        "  words = str.split()\n",
        "  N = len(words)\n",
        "  V = len(set(words))\n",
        "  return 10**4 * (-1/N + sum(word_frequency(str,i)*(i/N)**2 for i in range(1,V+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgsTPMHYlxP8"
      },
      "source": [
        "# returns the number of words of length k\n",
        "def k_char_cnt(str, k):\n",
        "  cnt = 0\n",
        "  words = str.split()\n",
        "  \n",
        "  for word in words:\n",
        "    if len(word) == k:\n",
        "      cnt += 1\n",
        "  \n",
        "  return cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIi2qvipWVh_"
      },
      "source": [
        "## using hazm lib\n",
        "tagger = POSTagger(model='/content/resources/postagger.model')\n",
        "def pronoun_ratio(txt):\n",
        "  word_tag = tagger.tag(word_tokenize(txt))\n",
        "  a = len(list(filter(lambda w:(w[1]=='V') and (w[0][-2:]!='یم') and  (w[0][-1:]=='م'), word_tag)))\n",
        "  b = len(list(filter(lambda w:w[1]=='PRO', word_tag)))\n",
        "  if b != 0 :\n",
        "    return a/b\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZkmJ-lXxMrh"
      },
      "source": [
        "Feature1 : number of character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R-XuEuCnyBU"
      },
      "source": [
        "df['F1'] = df.apply(lambda row: len(row.Comment), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZMHwr9ljL_u"
      },
      "source": [
        "Feature 2: The number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UB1XYKxjR9H"
      },
      "source": [
        "df['F2'] = df.apply(lambda row: len(row.Text.split()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxZXhU1bX8z"
      },
      "source": [
        "Feature 3: Vocabulary richness\n",
        "\n",
        "unique words count / total words count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnlcbqL9b_zO"
      },
      "source": [
        "df['F3'] = df.apply(lambda row: len(set(row.Text.split())) / len(row.Text.split()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-7o0SyXfN6v"
      },
      "source": [
        "Feature 4 :  (hapax dislegomena) / N\n",
        "\n",
        "A hapax dislegomena is a word or an expression that occurs only twice within a context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY1hpfLLf1IF"
      },
      "source": [
        "df['F4'] = df.apply(lambda row: word_frequency(row.Text,2), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOG733HFxRvk"
      },
      "source": [
        "Feature5 : yule's k measure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBRi5eLEcaCH"
      },
      "source": [
        "df['F5'] = df.apply(lambda row: yulesk(row.Text), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOfNW7LdlRpE"
      },
      "source": [
        "Feature 6: The number of single-character words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9aO1v6ylhkv"
      },
      "source": [
        "df['F6'] = df.apply(lambda row: k_char_cnt(row.Text, 1), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azvr-3w7eWib"
      },
      "source": [
        "Feature 7: Alphabet letters count\n",
        "\n",
        "alphabet letters count / total characters count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbWolLpYhtaw"
      },
      "source": [
        "df['F7'] = df.apply(lambda row: sum(c.isalpha() for c in row.Comment) / len(row.Comment), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nEUkWRkm3H"
      },
      "source": [
        "Feature 8 : (hapax legomena) / N\n",
        "\n",
        "A hapax legomena is a word or an expression that occurs only once within a context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O96le_GdkqX-"
      },
      "source": [
        "df['F8'] = df.apply(lambda row: word_frequency(row.Text,1), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AigESsz1tgw"
      },
      "source": [
        "Feature 9 :First person connected pronoun / other pronouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FICTC00842t"
      },
      "source": [
        "df['F9'] = df.apply(lambda row: pronoun_ratio(row.Comment), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmDsfuO-Ocet"
      },
      "source": [
        "Feature 10: The number of lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nhcojuOsHc"
      },
      "source": [
        "df['F10'] = df.apply(lambda row: row.Comment.count('\\n') + 1, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RKi0kBow2hRc",
        "outputId": "42cb1df2-9044-411e-8aa0-e59ba3783fe5"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Words</th>\n",
              "      <th>Gender</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...</td>\n",
              "      <td>اتاق کثیف پرسنل برخورد خوب داشت#دار خوب نزدیک ...</td>\n",
              "      <td>[اتاقها, کثیف, بود, ., پرسنل, برخورد, خوبی, ند...</td>\n",
              "      <td>female</td>\n",
              "      <td>76</td>\n",
              "      <td>10</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>-880.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828947</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...</td>\n",
              "      <td>سلا ببخشید می‌خواس بدون ایا عاد پول اینجا چقدر...</td>\n",
              "      <td>[سلام, ببخشید, می, خواستم, بدونم, در, ایام, عا...</td>\n",
              "      <td>female</td>\n",
              "      <td>66</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-900.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>من میخواستم برم کیش موندم کدام هتل را برم ولی ...</td>\n",
              "      <td>میخواس بر ک موند هتل بر تواین سا دید هتل مر تع...</td>\n",
              "      <td>[من, میخواستم, برم, کیش, موندم, کدام, هتل, را,...</td>\n",
              "      <td>female</td>\n",
              "      <td>219</td>\n",
              "      <td>32</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>-300.903320</td>\n",
              "      <td>2</td>\n",
              "      <td>0.812785</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من در مرداد ماه به همراه خواهرم و پسرش و دخترم...</td>\n",
              "      <td>مرداد ماه همراه خواهر پسر دختر درهتل بود#باش ص...</td>\n",
              "      <td>[من, در, مرداد, ماه, به, همراه, خواهرم, و, پسر...</td>\n",
              "      <td>female</td>\n",
              "      <td>467</td>\n",
              "      <td>63</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>-155.410783</td>\n",
              "      <td>0</td>\n",
              "      <td>0.792291</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...</td>\n",
              "      <td>سلا دیروز ک اومد رفتن این نظر خوند برگ ندا نظر...</td>\n",
              "      <td>[سلام, ., من, دیروز, از, کیش, اومدم, ., قبل, ر...</td>\n",
              "      <td>female</td>\n",
              "      <td>204</td>\n",
              "      <td>31</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-308.146756</td>\n",
              "      <td>2</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...</td>\n",
              "      <td>سلا دوس ک برگ هتل آنا رو برا اقام انتخاب کرد#ک...</td>\n",
              "      <td>[سلام, من, با, دوستم, تازه, از, کیش, برگشتیم, ...</td>\n",
              "      <td>male</td>\n",
              "      <td>644</td>\n",
              "      <td>92</td>\n",
              "      <td>0.684783</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>-106.229966</td>\n",
              "      <td>1</td>\n",
              "      <td>0.784161</td>\n",
              "      <td>0.510870</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...</td>\n",
              "      <td>بخ هتل نوساز شیک تره بخ ویلا خوبه ظاهرا اتاق ب...</td>\n",
              "      <td>[بخش, هتلی, نوسازتر, و, شیک, تره, ., اما, بخش,...</td>\n",
              "      <td>male</td>\n",
              "      <td>179</td>\n",
              "      <td>25</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>-377.600000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.787709</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...</td>\n",
              "      <td>سلا سال هفته اسفند ذر این هتل اقام دا هتل نسب ...</td>\n",
              "      <td>[با, سلام, من, سال, پیش, هفته, دوم, اسفند, ذر,...</td>\n",
              "      <td>male</td>\n",
              "      <td>340</td>\n",
              "      <td>50</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>-190.880000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.744118</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>وای از سرو صدا</td>\n",
              "      <td>وا سرو صدا</td>\n",
              "      <td>[وای, از, سرو, صدا]</td>\n",
              "      <td>male</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2222.222222</td>\n",
              "      <td>0</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>سلام من به همراه همسرم و مادر و برادر همسرم در...</td>\n",
              "      <td>سلا همراه همسر مادر برادر همسر این هتل زیبا اق...</td>\n",
              "      <td>[سلام, من, به, همراه, همسرم, و, مادر, و, برادر...</td>\n",
              "      <td>male</td>\n",
              "      <td>247</td>\n",
              "      <td>35</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>-271.486880</td>\n",
              "      <td>2</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  ... F10\n",
              "0     اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...  ...   1\n",
              "1     سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...  ...   2\n",
              "2     من میخواستم برم کیش موندم کدام هتل را برم ولی ...  ...   1\n",
              "3     من در مرداد ماه به همراه خواهرم و پسرش و دخترم...  ...   1\n",
              "4     سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...  ...   1\n",
              "...                                                 ...  ...  ..\n",
              "1995  سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...  ...   8\n",
              "1996  بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...  ...   1\n",
              "1997  با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...  ...   1\n",
              "1998                                     وای از سرو صدا  ...   1\n",
              "1999  سلام من به همراه همسرم و مادر و برادر همسرم در...  ...   1\n",
              "\n",
              "[2000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6fqyl86ehcE"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGTBxtopejyV",
        "outputId": "dfb35242-7880-44b7-87ea-ba23590ad765"
      },
      "source": [
        "normalized_df = pd.concat([df.iloc[:,:4], (df.iloc[:,4:] - df.iloc[:,4:].min()) / (df.iloc[:,4:].max() - df.iloc[:,4:].min())], axis=1)\n",
        "normalized_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Words</th>\n",
              "      <th>Gender</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...</td>\n",
              "      <td>اتاق کثیف پرسنل برخورد خوب داشت#دار خوب نزدیک ...</td>\n",
              "      <td>[اتاقها, کثیف, بود, ., پرسنل, برخورد, خوبی, ند...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.010415</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.648000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.633887</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...</td>\n",
              "      <td>سلا ببخشید می‌خواس بدون ایا عاد پول اینجا چقدر...</td>\n",
              "      <td>[سلام, ببخشید, می, خواستم, بدونم, در, ایام, عا...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610845</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.025641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>من میخواستم برم کیش موندم کدام هتل را برم ولی ...</td>\n",
              "      <td>میخواس بر ک موند هتل بر تواین سا دید هتل مر تع...</td>\n",
              "      <td>[من, میخواستم, برم, کیش, موندم, کدام, هتل, را,...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.030818</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.879639</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.599295</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من در مرداد ماه به همراه خواهرم و پسرش و دخترم...</td>\n",
              "      <td>مرداد ماه همراه خواهر پسر دختر درهتل بود#باش ص...</td>\n",
              "      <td>[من, در, مرداد, ماه, به, همراه, خواهرم, و, پسر...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.066201</td>\n",
              "      <td>0.064315</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.937836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555430</td>\n",
              "      <td>0.662698</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...</td>\n",
              "      <td>سلا دیروز ک اومد رفتن این نظر خوند برگ ندا نظر...</td>\n",
              "      <td>[سلام, ., من, دیروز, از, کیش, اومدم, ., قبل, ر...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.028677</td>\n",
              "      <td>0.031120</td>\n",
              "      <td>0.731183</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.876741</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.559340</td>\n",
              "      <td>0.637097</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...</td>\n",
              "      <td>سلا دوس ک برگ هتل آنا رو برا اقام انتخاب کرد#ک...</td>\n",
              "      <td>[سلام, من, با, دوستم, تازه, از, کیش, برگشتیم, ...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.091454</td>\n",
              "      <td>0.094398</td>\n",
              "      <td>0.474638</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.957508</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.538030</td>\n",
              "      <td>0.388587</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.179487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...</td>\n",
              "      <td>بخ هتل نوساز شیک تره بخ ویلا خوبه ظاهرا اتاق ب...</td>\n",
              "      <td>[بخش, هتلی, نوسازتر, و, شیک, تره, ., اما, بخش,...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.025111</td>\n",
              "      <td>0.024896</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.848960</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.545624</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...</td>\n",
              "      <td>سلا سال هفته اسفند ذر این هتل اقام دا هتل نسب ...</td>\n",
              "      <td>[با, سلام, من, سال, پیش, هفته, دوم, اسفند, ذر,...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.048081</td>\n",
              "      <td>0.050830</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.923648</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.452322</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>وای از سرو صدا</td>\n",
              "      <td>وا سرو صدا</td>\n",
              "      <td>[وای, از, سرو, صدا]</td>\n",
              "      <td>male</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.002075</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541353</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>سلام من به همراه همسرم و مادر و برادر همسرم در...</td>\n",
              "      <td>سلا همراه همسر مادر برادر همسر این هتل زیبا اق...</td>\n",
              "      <td>[سلام, من, به, همراه, همسرم, و, مادر, و, برادر...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.034812</td>\n",
              "      <td>0.035270</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.114286</td>\n",
              "      <td>0.891405</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.549400</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  ...       F10\n",
              "0     اتاقها کثیف بود.پرسنل برخورد خوبی نداشتند.فقط ...  ...  0.000000\n",
              "1     سلام\\nببخشید می خواستم بدونم در ایام عادی پول ...  ...  0.025641\n",
              "2     من میخواستم برم کیش موندم کدام هتل را برم ولی ...  ...  0.000000\n",
              "3     من در مرداد ماه به همراه خواهرم و پسرش و دخترم...  ...  0.000000\n",
              "4     سلام.من دیروز از کیش اومدم.قبل رفتن این نظرات ...  ...  0.000000\n",
              "...                                                 ...  ...       ...\n",
              "1995  سلام من با دوستم تازه از کیش برگشتیم\\nهتل آنا ...  ...  0.179487\n",
              "1996  بخش هتلی نوسازتر و شیک تره. اما بخش ویلایی هم ...  ...  0.000000\n",
              "1997  با سلام من سال پیش هفته دوم اسفند ذر این هتل ا...  ...  0.000000\n",
              "1998                                     وای از سرو صدا  ...  0.000000\n",
              "1999  سلام من به همراه همسرم و مادر و برادر همسرم در...  ...  0.000000\n",
              "\n",
              "[2000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG8z86D-W6Ml"
      },
      "source": [
        "df.to_csv (r'/content/dataframe.csv', index = False, header=True, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zgqO16pBETN"
      },
      "source": [
        "# Classification and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttZTdjYbms4E"
      },
      "source": [
        "Bert Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280,
          "referenced_widgets": [
            "963d1be30c2849e0922106c56e97df3f",
            "7be3ccb654404da4b7d8417dbc454d9a",
            "c0c33796693b4b189133ecdd8b799310",
            "880c43ac147a45a2afb92c56b3cc2efc",
            "4f3a3e6c4e73455f9f8c198e2125cbe9",
            "e953b6a1f4a14385ab60345fc9533c23",
            "a901bf460b6b430e950e00abf537d47b",
            "8d6cd2c81c174c92a357db59d84f0612",
            "a0b55d66f66048e98e9f3c8696939787",
            "c1ad6290d50442488100632ba4c9c3eb",
            "68d32554cd11448989b40fb6acc6bdb2",
            "8a80e8cb6c014590bfaff809e37219f6",
            "cbc7c7c580544f84ac68b1db7c76c32b",
            "ed55a5e6c18d48199dcf6caf7f9acce9",
            "7d09770f3cdf459c8bbf6e479b92b663",
            "dae014d379ee4d97947e40d8c83862f3",
            "01fed2083c8f41ec942a8651f4d8571b",
            "3f26798321cc4a09b4ce9a2696395fbe",
            "5868507df6f44ee1b265857636f330de",
            "06625d7c1a024832809eddf4458ab5c7",
            "ad1493167e9c4fe1bc37d5bcab49c65e",
            "c27148e2ed2c46d2bbf756c1d7f37652",
            "cb968689513f4c689c4a0b2fce4af2b8",
            "4df00a402cbb407a9fe7ef0bdfe0075d"
          ]
        },
        "id": "Ne4zno15mud0",
        "outputId": "7928d03d-100d-46de-dce0-e648ac6cfce3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoConfig, AutoTokenizer, TFAutoModel\n",
        "\n",
        "# v2.0\n",
        "config = AutoConfig.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
        "bertmodel = TFAutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "963d1be30c2849e0922106c56e97df3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0b55d66f66048e98e9f3c8696939787",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1198122.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01fed2083c8f41ec942a8651f4d8571b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=963211760.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvdf2odum08q",
        "outputId": "0d9a3c09-c2aa-4ea2-9853-9bacda4e1b21"
      },
      "source": [
        "X_bert=[]\n",
        "input_sentences  = [comment for comment in df.Comment]\n",
        "idx = 0\n",
        "for text in input_sentences:\n",
        "  idx = idx + 1\n",
        "  if (idx%10)==0:\n",
        "    print(f\"{idx:<4}\", end=' ')\n",
        "  if (idx%200)==0:\n",
        "    print()\n",
        "  input_ids = tf.constant(tokenizer.encode(text))[None, :]  \n",
        "  outputs = bertmodel(input_ids)\n",
        "  last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n",
        "  X_bert.append(np.sum(last_hidden_states[0].numpy(),axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10   20   30   40   50   60   70   80   90   100  110  120  130  140  150  160  170  180  190  200  \n",
            "210  220  230  240  250  260  270  280  290  300  310  320  330  340  350  360  370  380  390  400  \n",
            "410  420  430  440  450  460  470  480  490  500  510  520  530  540  550  560  570  580  590  600  \n",
            "610  620  630  640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790  800  \n",
            "810  820  830  840  850  860  870  880  890  900  910  920  930  940  950  960  970  980  990  1000 \n",
            "1010 1020 1030 1040 1050 1060 1070 1080 1090 1100 1110 1120 1130 1140 1150 1160 1170 1180 1190 1200 \n",
            "1210 1220 1230 1240 1250 1260 1270 1280 1290 1300 1310 1320 1330 1340 1350 1360 1370 1380 1390 1400 \n",
            "1410 1420 1430 1440 1450 1460 1470 1480 1490 1500 1510 1520 1530 1540 1550 1560 1570 1580 1590 1600 \n",
            "1610 1620 1630 1640 1650 1660 1670 1680 1690 1700 1710 1720 1730 1740 1750 1760 1770 1780 1790 1800 \n",
            "1810 1820 1830 1840 1850 1860 1870 1880 1890 1900 1910 1920 1930 1940 1950 1960 1970 1980 1990 2000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBnKXTTim-g6"
      },
      "source": [
        "X_b = np.array(X_bert)\n",
        "Y_b = np.array([0 if gnd=='female' else 1 for gnd in df['Gender']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i641eGa5m406"
      },
      "source": [
        "Word2Vec Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TOy4Jat3Lot",
        "outputId": "6545aa38-87d0-4e34-fc34-e579c9333a46"
      },
      "source": [
        "input_sentences  = [comment for comment in df.Words]\n",
        "\n",
        "X_dataset = np.array([model[txt].sum(axis=0) for txt in input_sentences])\n",
        "Y_dataset = np.array([0 if gnd=='female' else 1 for gnd in df['Gender']])\n",
        "\n",
        "#min_max_scaler = MinMaxScaler()\n",
        "#X_dataset = min_max_scaler.fit_transform(X_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E39KZU5l3Td9"
      },
      "source": [
        "Ensemble classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E192UlnugTd"
      },
      "source": [
        "def ensemble_classification(selected_clf):\n",
        "  kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "  scores = []\n",
        "  fold = 0\n",
        "  for train_index, test_index in kf.split(df.Gender):\n",
        "    fold = fold + 1\n",
        "    all_pred = []\n",
        "    for clfp in [classifiers_profile[idx] for idx in selected_clf]:\n",
        "        (x, y, clf, name, vectorizer) = clfp\n",
        "        x_train, x_test, y_train, y_test  = x[train_index], x[test_index], y[train_index], y[test_index]\n",
        "        \n",
        "        if vectorizer:\n",
        "          x_train = vectorizer.fit_transform(x_train)\n",
        "          x_test = vectorizer.transform(x_test)\n",
        "        \n",
        "        clf.fit(x_train, y_train)\n",
        "        \n",
        "        pred = clf.predict(x_test)\n",
        "        all_pred.append(pred)\n",
        "        print(f\"{name+':':<70}{accuracy_score(y_test, pred):<20}\")\n",
        "\n",
        "    all_pred = np.vstack(all_pred)\n",
        "    y_pred = ['male' if list(all_pred[:,idx]).count('male') > list(all_pred[:,idx]).count('female') else 'female' for idx in range(all_pred.shape[1])]\n",
        "    scores.append(accuracy_score(y_test, y_pred))\n",
        "    print(f\"\\nfold {fold:<10} ensemble accuracy:{accuracy_score(y_test, y_pred):<70}\\n\")\n",
        "\n",
        "  print(f\"final accuracy of ensemble classifier: {np.mean(scores):<70}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq3msiEkThtK"
      },
      "source": [
        "def classify_and_evaluate(x, y, clf, name, vectorizer=None):\n",
        "  kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "  scores = []\n",
        "  for train_index, test_index in kf.split(x):\n",
        "    x_train, x_test, y_train, y_test  = x[train_index], x[test_index], y[train_index], y[test_index]\n",
        "    if vectorizer:\n",
        "      x_train = vectorizer.fit_transform(x_train)\n",
        "      x_test = vectorizer.transform(x_test)\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred = clf.predict(x_test)\n",
        "    scores.append(accuracy_score(y_test, y_pred))\n",
        "  print(f\"{name}:{' ' * (70 - len(name))}{np.mean(scores)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZjnJh2DV54Y"
      },
      "source": [
        "# Source: https://github.com/rlphilli/sklearn-PUK-kernel\n",
        "def PUK_kernel(X1,X2, sigma=1.0, omega=1.0):\n",
        "    # Compute the kernel matrix between two arrays using the Pearson VII function-based universal kernel.\n",
        "\n",
        "    # Compute squared euclidean distance between each row element pair of the two matrices\n",
        "    if X1 is X2 :\n",
        "        kernel = squareform(pdist(X1, 'sqeuclidean'))\n",
        "    else:\n",
        "        kernel = cdist(X1, X2, 'sqeuclidean')\n",
        "\n",
        "    kernel = (1 + (kernel * 4 * np.sqrt(2**(1.0/omega)-1)) / sigma**2) ** omega\n",
        "    kernel = 1/kernel\n",
        "\n",
        "    return kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaEcWf8Mcqym"
      },
      "source": [
        "# Source: https://github.com/rlphilli/sklearn-PUK-kernel --- with minor changes\n",
        "def modified_PUK_kernel(X1,X2, sigma=1.0, omega=1.0):\n",
        "    # Compute the kernel matrix between two arrays using the Pearson VII function-based universal kernel.\n",
        "\n",
        "    # Compute squared euclidean distance between each row element pair of the two matrices\n",
        "    if X1 is X2 :\n",
        "        kernel = squareform(pdist(X1.todense(), 'sqeuclidean'))\n",
        "    else:\n",
        "        kernel = cdist(X1.todense(), X2.todense(), 'sqeuclidean')\n",
        "\n",
        "    kernel = (1 + (kernel * 4 * np.sqrt(2**(1.0/omega)-1)) / sigma**2) ** omega\n",
        "    kernel = 1/kernel\n",
        "\n",
        "    return kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkk_JFxkTjLC"
      },
      "source": [
        "classifiers_profile = [\n",
        "        (X_b, Y_b, svm.SVC(kernel='rbf'), 'SVM with Bert on raw data (kernel: RBF)',None),\n",
        "        (X_dataset, Y_dataset, LogisticRegression(solver='liblinear', max_iter=500), 'LogisticRegression with Word2Vec on raw data (solver=liblinear)',None),\n",
        "        (df.Comment, df.Gender, LogisticRegression(solver='liblinear', max_iter=500), 'LogisticRegression with TfidfVector on raw data', TfidfVectorizer()),\n",
        "        (df.Comment, df.Gender, LogisticRegression(solver='liblinear', max_iter=500), 'LogisticRegression with CountVector on raw data', CountVectorizer()),\n",
        "        (df.Comment, df.Gender, MultinomialNB(), 'MultinomalNB with CountVector on raw data', CountVectorizer()),\n",
        "        (df.Text, df.Gender, MultinomialNB(), 'MultinomalNB with CountVector on preprocessed data', CountVectorizer()),\n",
        "        (pd.concat([df.iloc[:,4:8], df.iloc[:,9:]], axis=1).to_numpy(), df.Gender, MultinomialNB(), 'MultinomalNB with features',None),\n",
        "        (normalized_df.iloc[:, 4:].to_numpy(), df.Gender, MultinomialNB(), 'MultinomalNB with normalized features',None),\n",
        "        (X_dataset, Y_dataset, svm.SVC(kernel='rbf'), 'SVM with Word2Vec on raw data (kernel: RBF)',None),\n",
        "        # The following line has been turned into a comment because it needs an immense amount of time to execute.\n",
        "        #(X_dataset, Y_dataset, svm.SVC(kernel='linear'), 'SVM with Word2Vec on raw data (kernel: Linear)',None),\n",
        "        (X_dataset, Y_dataset, svm.SVC(kernel=PUK_kernel), 'SVM with Word2Vec on raw data (kernel: Pearson VII)',None),\n",
        "        (df.Comment, df.Gender, svm.SVC(kernel='rbf'), 'SVM with TfidfVector on raw data (kernel: RBF)', TfidfVectorizer()),\n",
        "        (df.Comment, df.Gender, svm.SVC(kernel='linear'), 'SVM with TfidfVector on raw data (kernel: Linear)', TfidfVectorizer()),\n",
        "        (df.Comment, df.Gender, svm.SVC(kernel=modified_PUK_kernel), 'SVM with TfidfVector on raw data (kernel: Pearson VII)', TfidfVectorizer()),\n",
        "        (df.Text, df.Gender, svm.SVC(kernel='rbf'), 'SVM with TfidfVector on preprocessed data (kernel: RBF)', TfidfVectorizer()),\n",
        "        (df.Text, df.Gender, svm.SVC(kernel='linear'), 'SVM with TfidfVector on preprocessed data (kernel: Linear)', TfidfVectorizer()),\n",
        "        (df.Text, df.Gender, svm.SVC(kernel=modified_PUK_kernel), 'SVM with TfidfVector on preprocessed data (kernel: Pearson VII)', TfidfVectorizer()),\n",
        "        (df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='rbf'), 'SVM with features (kernel: RBF)',None),\n",
        "        (df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='linear'), 'SVM with features (kernel: Linear)'),\n",
        "        (df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel=PUK_kernel), 'SVM with features (kernel: Pearson VII)'),\n",
        "        (normalized_df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='rbf'), 'SVM with normalized features (kernel: RBF)',None),\n",
        "        (normalized_df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='linear'), 'SVM with normalized features (kernel: Linear)'),\n",
        "        (normalized_df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel=PUK_kernel), 'SVM with normalized features (kernel: Pearson VII)'),\n",
        "        (X_dataset, Y_dataset, tree.DecisionTreeClassifier(), 'Decision Tree with Word2Vec on raw data',None),\n",
        "        (df.Comment, df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with CountVector on raw data', CountVectorizer()),\n",
        "        (df.Comment, df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with CountVector on preprocessed data', CountVectorizer()),\n",
        "        (df.iloc[:, 4:].to_numpy(), df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with features',None),\n",
        "        (normalized_df.iloc[:, 4:].to_numpy(), df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with normalized features',None),\n",
        "        (X_dataset, Y_dataset, AdaBoostClassifier(n_estimators=100, random_state=0), 'AdaBoostClassifier with Word2Vec on raw data',None),\n",
        "        (df.Comment, df.Gender, AdaBoostClassifier(n_estimators=100, random_state=0), 'AdaBoostClassifier with TfidfVector on raw data', TfidfVectorizer())\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE5imLLstDGS",
        "outputId": "4d7d880f-c13d-4b58-eb07-18a330c0d52d"
      },
      "source": [
        "out = [classify_and_evaluate(*clfp) for clfp in classifiers_profile]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM with Bert on raw data (kernel: RBF):                               0.6015\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):       0.6224999999999999\n",
            "LogisticRegression with TfidfVector on raw data:                       0.6275\n",
            "LogisticRegression with CountVector on raw data:                       0.5895\n",
            "MultinomalNB with CountVector on raw data:                             0.629\n",
            "MultinomalNB with CountVector on preprocessed data:                    0.607\n",
            "MultinomalNB with features:                                            0.5625\n",
            "MultinomalNB with normalized features:                                 0.5424999999999999\n",
            "SVM with Word2Vec on raw data (kernel: RBF):                           0.609\n",
            "SVM with Word2Vec on raw data (kernel: Pearson VII):                   0.4715\n",
            "SVM with TfidfVector on raw data (kernel: RBF):                        0.6259999999999999\n",
            "SVM with TfidfVector on raw data (kernel: Linear):                     0.613\n",
            "SVM with TfidfVector on raw data (kernel: Pearson VII):                0.6195\n",
            "SVM with TfidfVector on preprocessed data (kernel: RBF):               0.6094999999999999\n",
            "SVM with TfidfVector on preprocessed data (kernel: Linear):            0.607\n",
            "SVM with TfidfVector on preprocessed data (kernel: Pearson VII):       0.605\n",
            "SVM with features (kernel: RBF):                                       0.5109999999999999\n",
            "SVM with features (kernel: Linear):                                    0.5469999999999999\n",
            "SVM with features (kernel: Pearson VII):                               0.5085\n",
            "SVM with normalized features (kernel: RBF):                            0.5355000000000001\n",
            "SVM with normalized features (kernel: Linear):                         0.5255000000000001\n",
            "SVM with normalized features (kernel: Pearson VII):                    0.5519999999999999\n",
            "Decision Tree with Word2Vec on raw data:                               0.542\n",
            "Decision Tree with CountVector on raw data:                            0.5479999999999999\n",
            "Decision Tree with CountVector on preprocessed data:                   0.5355\n",
            "Decision Tree with features:                                           0.5295\n",
            "Decision Tree with normalized features:                                0.522\n",
            "AdaBoostClassifier with Word2Vec on raw data:                          0.569\n",
            "AdaBoostClassifier with TfidfVector on raw data:                       0.5894999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBU0GQJJtSI8"
      },
      "source": [
        "Ensemble classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsPvjSmLtPaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3f4b30-fa43-4d09-fe8f-bb7a7f0253ca"
      },
      "source": [
        "classifiers = [1, 2, 4, 10, 11]\n",
        "ensemble_classification(classifiers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.655               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.65                \n",
            "MultinomalNB with CountVector on raw data:                            0.67                \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.655               \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.63                \n",
            "\n",
            "fold 1          ensembl accuracy:0.655                                                                 \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.64                \n",
            "LogisticRegression with TfidfVector on raw data:                      0.635               \n",
            "MultinomalNB with CountVector on raw data:                            0.635               \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.635               \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.64                \n",
            "\n",
            "fold 2          ensembl accuracy:0.65                                                                  \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.625               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.67                \n",
            "MultinomalNB with CountVector on raw data:                            0.68                \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.68                \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.62                \n",
            "\n",
            "fold 3          ensembl accuracy:0.67                                                                  \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.67                \n",
            "LogisticRegression with TfidfVector on raw data:                      0.665               \n",
            "MultinomalNB with CountVector on raw data:                            0.625               \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.68                \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.64                \n",
            "\n",
            "fold 4          ensembl accuracy:0.665                                                                 \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.61                \n",
            "LogisticRegression with TfidfVector on raw data:                      0.625               \n",
            "MultinomalNB with CountVector on raw data:                            0.58                \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.615               \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.595               \n",
            "\n",
            "fold 5          ensembl accuracy:0.635                                                                 \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.625               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.63                \n",
            "MultinomalNB with CountVector on raw data:                            0.6                 \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.61                \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.615               \n",
            "\n",
            "fold 6          ensembl accuracy:0.635                                                                 \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.645               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.62                \n",
            "MultinomalNB with CountVector on raw data:                            0.635               \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.625               \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.615               \n",
            "\n",
            "fold 7          ensembl accuracy:0.63                                                                  \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.645               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.63                \n",
            "MultinomalNB with CountVector on raw data:                            0.615               \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.615               \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.625               \n",
            "\n",
            "fold 8          ensembl accuracy:0.63                                                                  \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.605               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.635               \n",
            "MultinomalNB with CountVector on raw data:                            0.675               \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.66                \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.645               \n",
            "\n",
            "fold 9          ensembl accuracy:0.665                                                                 \n",
            "\n",
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.605               \n",
            "LogisticRegression with TfidfVector on raw data:                      0.585               \n",
            "MultinomalNB with CountVector on raw data:                            0.62                \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.59                \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.585               \n",
            "\n",
            "fold 10         ensembl accuracy:0.61                                                                  \n",
            "\n",
            "final accuracy of ensembl classifier: 0.6445000000000001                                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qca7vBhTjLHx"
      },
      "source": [
        "# Evaluation on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma9ysPC0jcSa",
        "outputId": "15358f21-2f6f-45d6-92ca-81920e115ff4"
      },
      "source": [
        "!unzip -o /content/NLP-Assignments/test.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/NLP-Assignments/test.zip\n",
            "   creating: test/\n",
            "   creating: test/female/\n",
            "  inflating: test/female/1001.txt    \n",
            "  inflating: test/female/1002.txt    \n",
            "  inflating: test/female/1003.txt    \n",
            "  inflating: test/female/1004.txt    \n",
            "  inflating: test/female/1005.txt    \n",
            "  inflating: test/female/1006.txt    \n",
            "  inflating: test/female/1007.txt    \n",
            "  inflating: test/female/1008.txt    \n",
            "  inflating: test/female/1009.txt    \n",
            "  inflating: test/female/1010.txt    \n",
            "  inflating: test/female/1011.txt    \n",
            "  inflating: test/female/1012.txt    \n",
            "  inflating: test/female/1013.txt    \n",
            "  inflating: test/female/1014.txt    \n",
            "  inflating: test/female/1015.txt    \n",
            "  inflating: test/female/1016.txt    \n",
            "  inflating: test/female/1017.txt    \n",
            "  inflating: test/female/1018.txt    \n",
            "  inflating: test/female/1019.txt    \n",
            "  inflating: test/female/1020.txt    \n",
            "  inflating: test/female/1021.txt    \n",
            "  inflating: test/female/1022.txt    \n",
            "  inflating: test/female/1023.txt    \n",
            "  inflating: test/female/1024.txt    \n",
            "  inflating: test/female/1025.txt    \n",
            "  inflating: test/female/1026.txt    \n",
            "  inflating: test/female/1027.txt    \n",
            "  inflating: test/female/1028.txt    \n",
            "  inflating: test/female/1029.txt    \n",
            "  inflating: test/female/1030.txt    \n",
            "  inflating: test/female/1031.txt    \n",
            "  inflating: test/female/1032.txt    \n",
            "  inflating: test/female/1033.txt    \n",
            "  inflating: test/female/1034.txt    \n",
            "  inflating: test/female/1035.txt    \n",
            "  inflating: test/female/1036.txt    \n",
            "  inflating: test/female/1037.txt    \n",
            "  inflating: test/female/1038.txt    \n",
            "  inflating: test/female/1039.txt    \n",
            "  inflating: test/female/1040.txt    \n",
            "  inflating: test/female/1041.txt    \n",
            "  inflating: test/female/1042.txt    \n",
            "  inflating: test/female/1043.txt    \n",
            "  inflating: test/female/1044.txt    \n",
            "  inflating: test/female/1045.txt    \n",
            "  inflating: test/female/1046.txt    \n",
            "  inflating: test/female/1047.txt    \n",
            "  inflating: test/female/1048.txt    \n",
            "  inflating: test/female/1049.txt    \n",
            "  inflating: test/female/1050.txt    \n",
            "  inflating: test/female/1051.txt    \n",
            "  inflating: test/female/1052.txt    \n",
            "  inflating: test/female/1053.txt    \n",
            "  inflating: test/female/1054.txt    \n",
            "  inflating: test/female/1055.txt    \n",
            "  inflating: test/female/1056.txt    \n",
            "  inflating: test/female/1057.txt    \n",
            "  inflating: test/female/1058.txt    \n",
            "  inflating: test/female/1059.txt    \n",
            "  inflating: test/female/1060.txt    \n",
            "  inflating: test/female/1061.txt    \n",
            "  inflating: test/female/1062.txt    \n",
            "  inflating: test/female/1063.txt    \n",
            "  inflating: test/female/1064.txt    \n",
            "  inflating: test/female/1065.txt    \n",
            "  inflating: test/female/1066.txt    \n",
            "  inflating: test/female/1067.txt    \n",
            "  inflating: test/female/1068.txt    \n",
            "  inflating: test/female/1069.txt    \n",
            "  inflating: test/female/1070.txt    \n",
            "  inflating: test/female/1071.txt    \n",
            "  inflating: test/female/1072.txt    \n",
            "  inflating: test/female/1073.txt    \n",
            "  inflating: test/female/1074.txt    \n",
            "  inflating: test/female/1075.txt    \n",
            "  inflating: test/female/1076.txt    \n",
            "  inflating: test/female/1077.txt    \n",
            "  inflating: test/female/1078.txt    \n",
            "  inflating: test/female/1079.txt    \n",
            "  inflating: test/female/1080.txt    \n",
            "  inflating: test/female/1081.txt    \n",
            "  inflating: test/female/1082.txt    \n",
            "  inflating: test/female/1083.txt    \n",
            "  inflating: test/female/1084.txt    \n",
            "  inflating: test/female/1085.txt    \n",
            "  inflating: test/female/1086.txt    \n",
            "  inflating: test/female/1087.txt    \n",
            "  inflating: test/female/1088.txt    \n",
            "  inflating: test/female/1089.txt    \n",
            "  inflating: test/female/1090.txt    \n",
            "  inflating: test/female/1091.txt    \n",
            "  inflating: test/female/1092.txt    \n",
            "  inflating: test/female/1093.txt    \n",
            "  inflating: test/female/1094.txt    \n",
            "  inflating: test/female/1095.txt    \n",
            "  inflating: test/female/1096.txt    \n",
            "  inflating: test/female/1097.txt    \n",
            "  inflating: test/female/1098.txt    \n",
            "  inflating: test/female/1099.txt    \n",
            "  inflating: test/female/1100.txt    \n",
            "  inflating: test/female/1101.txt    \n",
            "  inflating: test/female/1102.txt    \n",
            "  inflating: test/female/1103.txt    \n",
            "  inflating: test/female/1104.txt    \n",
            "  inflating: test/female/1105.txt    \n",
            "  inflating: test/female/1106.txt    \n",
            "  inflating: test/female/1107.txt    \n",
            "  inflating: test/female/1108.txt    \n",
            "  inflating: test/female/1109.txt    \n",
            "  inflating: test/female/1110.txt    \n",
            "  inflating: test/female/1111.txt    \n",
            "  inflating: test/female/1112.txt    \n",
            "  inflating: test/female/1113.txt    \n",
            "  inflating: test/female/1114.txt    \n",
            "  inflating: test/female/1115.txt    \n",
            "  inflating: test/female/1116.txt    \n",
            "  inflating: test/female/1117.txt    \n",
            "  inflating: test/female/1118.txt    \n",
            "  inflating: test/female/1119.txt    \n",
            "  inflating: test/female/1120.txt    \n",
            "  inflating: test/female/1121.txt    \n",
            "  inflating: test/female/1122.txt    \n",
            "  inflating: test/female/1123.txt    \n",
            "  inflating: test/female/1124.txt    \n",
            "  inflating: test/female/1125.txt    \n",
            "  inflating: test/female/1126.txt    \n",
            "  inflating: test/female/1127.txt    \n",
            "  inflating: test/female/1128.txt    \n",
            "  inflating: test/female/1129.txt    \n",
            "  inflating: test/female/1130.txt    \n",
            "  inflating: test/female/1131.txt    \n",
            "  inflating: test/female/1132.txt    \n",
            "  inflating: test/female/1133.txt    \n",
            "  inflating: test/female/1134.txt    \n",
            "  inflating: test/female/1135.txt    \n",
            "  inflating: test/female/1136.txt    \n",
            "  inflating: test/female/1137.txt    \n",
            "  inflating: test/female/1138.txt    \n",
            "  inflating: test/female/1139.txt    \n",
            "  inflating: test/female/1140.txt    \n",
            "  inflating: test/female/1141.txt    \n",
            "  inflating: test/female/1142.txt    \n",
            "  inflating: test/female/1143.txt    \n",
            "  inflating: test/female/1144.txt    \n",
            "  inflating: test/female/1145.txt    \n",
            "  inflating: test/female/1146.txt    \n",
            "  inflating: test/female/1147.txt    \n",
            "  inflating: test/female/1148.txt    \n",
            "  inflating: test/female/1149.txt    \n",
            "  inflating: test/female/1150.txt    \n",
            "  inflating: test/female/1151.txt    \n",
            "  inflating: test/female/1152.txt    \n",
            "  inflating: test/female/1153.txt    \n",
            "  inflating: test/female/1154.txt    \n",
            "  inflating: test/female/1155.txt    \n",
            "  inflating: test/female/1156.txt    \n",
            "  inflating: test/female/1157.txt    \n",
            "  inflating: test/female/1158.txt    \n",
            "  inflating: test/female/1159.txt    \n",
            "  inflating: test/female/1160.txt    \n",
            "  inflating: test/female/1161.txt    \n",
            "  inflating: test/female/1162.txt    \n",
            "  inflating: test/female/1163.txt    \n",
            "  inflating: test/female/1164.txt    \n",
            "  inflating: test/female/1165.txt    \n",
            "  inflating: test/female/1166.txt    \n",
            "  inflating: test/female/1167.txt    \n",
            "  inflating: test/female/1168.txt    \n",
            "  inflating: test/female/1169.txt    \n",
            "  inflating: test/female/1170.txt    \n",
            "  inflating: test/female/1171.txt    \n",
            "  inflating: test/female/1172.txt    \n",
            "  inflating: test/female/1173.txt    \n",
            "  inflating: test/female/1174.txt    \n",
            "  inflating: test/female/1175.txt    \n",
            "  inflating: test/female/1176.txt    \n",
            "  inflating: test/female/1177.txt    \n",
            "  inflating: test/female/1178.txt    \n",
            "  inflating: test/female/1179.txt    \n",
            "  inflating: test/female/1180.txt    \n",
            "  inflating: test/female/1181.txt    \n",
            "  inflating: test/female/1182.txt    \n",
            "  inflating: test/female/1183.txt    \n",
            "  inflating: test/female/1184.txt    \n",
            "  inflating: test/female/1185.txt    \n",
            "  inflating: test/female/1186.txt    \n",
            "  inflating: test/female/1187.txt    \n",
            "  inflating: test/female/1188.txt    \n",
            "  inflating: test/female/1189.txt    \n",
            "   creating: test/male/\n",
            "  inflating: test/male/1001.txt      \n",
            "  inflating: test/male/1002.txt      \n",
            "  inflating: test/male/1003.txt      \n",
            "  inflating: test/male/1004.txt      \n",
            "  inflating: test/male/1005.txt      \n",
            "  inflating: test/male/1006.txt      \n",
            "  inflating: test/male/1007.txt      \n",
            "  inflating: test/male/1008.txt      \n",
            "  inflating: test/male/1009.txt      \n",
            "  inflating: test/male/1010.txt      \n",
            "  inflating: test/male/1011.txt      \n",
            "  inflating: test/male/1012.txt      \n",
            "  inflating: test/male/1013.txt      \n",
            "  inflating: test/male/1014.txt      \n",
            "  inflating: test/male/1015.txt      \n",
            "  inflating: test/male/1016.txt      \n",
            "  inflating: test/male/1017.txt      \n",
            "  inflating: test/male/1018.txt      \n",
            "  inflating: test/male/1019.txt      \n",
            "  inflating: test/male/1020.txt      \n",
            "  inflating: test/male/1021.txt      \n",
            "  inflating: test/male/1022.txt      \n",
            "  inflating: test/male/1023.txt      \n",
            "  inflating: test/male/1024.txt      \n",
            "  inflating: test/male/1025.txt      \n",
            "  inflating: test/male/1026.txt      \n",
            "  inflating: test/male/1027.txt      \n",
            "  inflating: test/male/1028.txt      \n",
            "  inflating: test/male/1029.txt      \n",
            "  inflating: test/male/1030.txt      \n",
            "  inflating: test/male/1031.txt      \n",
            "  inflating: test/male/1032.txt      \n",
            "  inflating: test/male/1033.txt      \n",
            "  inflating: test/male/1034.txt      \n",
            "  inflating: test/male/1035.txt      \n",
            "  inflating: test/male/1036.txt      \n",
            "  inflating: test/male/1037.txt      \n",
            "  inflating: test/male/1038.txt      \n",
            "  inflating: test/male/1039.txt      \n",
            "  inflating: test/male/1040.txt      \n",
            "  inflating: test/male/1041.txt      \n",
            "  inflating: test/male/1042.txt      \n",
            "  inflating: test/male/1043.txt      \n",
            "  inflating: test/male/1044.txt      \n",
            "  inflating: test/male/1045.txt      \n",
            "  inflating: test/male/1046.txt      \n",
            "  inflating: test/male/1047.txt      \n",
            "  inflating: test/male/1048.txt      \n",
            "  inflating: test/male/1049.txt      \n",
            "  inflating: test/male/1050.txt      \n",
            "  inflating: test/male/1051.txt      \n",
            "  inflating: test/male/1052.txt      \n",
            "  inflating: test/male/1053.txt      \n",
            "  inflating: test/male/1054.txt      \n",
            "  inflating: test/male/1055.txt      \n",
            "  inflating: test/male/1056.txt      \n",
            "  inflating: test/male/1057.txt      \n",
            "  inflating: test/male/1058.txt      \n",
            "  inflating: test/male/1059.txt      \n",
            "  inflating: test/male/1060.txt      \n",
            "  inflating: test/male/1061.txt      \n",
            "  inflating: test/male/1062.txt      \n",
            "  inflating: test/male/1063.txt      \n",
            "  inflating: test/male/1064.txt      \n",
            "  inflating: test/male/1065.txt      \n",
            "  inflating: test/male/1066.txt      \n",
            "  inflating: test/male/1067.txt      \n",
            "  inflating: test/male/1068.txt      \n",
            "  inflating: test/male/1069.txt      \n",
            "  inflating: test/male/1070.txt      \n",
            "  inflating: test/male/1071.txt      \n",
            "  inflating: test/male/1072.txt      \n",
            "  inflating: test/male/1073.txt      \n",
            "  inflating: test/male/1074.txt      \n",
            "  inflating: test/male/1075.txt      \n",
            "  inflating: test/male/1076.txt      \n",
            "  inflating: test/male/1077.txt      \n",
            "  inflating: test/male/1078.txt      \n",
            "  inflating: test/male/1079.txt      \n",
            "  inflating: test/male/1080.txt      \n",
            "  inflating: test/male/1081.txt      \n",
            "  inflating: test/male/1082.txt      \n",
            "  inflating: test/male/1083.txt      \n",
            "  inflating: test/male/1084.txt      \n",
            "  inflating: test/male/1085.txt      \n",
            "  inflating: test/male/1086.txt      \n",
            "  inflating: test/male/1087.txt      \n",
            "  inflating: test/male/1088.txt      \n",
            "  inflating: test/male/1089.txt      \n",
            "  inflating: test/male/1090.txt      \n",
            "  inflating: test/male/1091.txt      \n",
            "  inflating: test/male/1092.txt      \n",
            "  inflating: test/male/1093.txt      \n",
            "  inflating: test/male/1094.txt      \n",
            "  inflating: test/male/1095.txt      \n",
            "  inflating: test/male/1096.txt      \n",
            "  inflating: test/male/1097.txt      \n",
            "  inflating: test/male/1098.txt      \n",
            "  inflating: test/male/1099.txt      \n",
            "  inflating: test/male/1100.txt      \n",
            "  inflating: test/male/1101.txt      \n",
            "  inflating: test/male/1102.txt      \n",
            "  inflating: test/male/1103.txt      \n",
            "  inflating: test/male/1104.txt      \n",
            "  inflating: test/male/1105.txt      \n",
            "  inflating: test/male/1106.txt      \n",
            "  inflating: test/male/1107.txt      \n",
            "  inflating: test/male/1108.txt      \n",
            "  inflating: test/male/1109.txt      \n",
            "  inflating: test/male/1110.txt      \n",
            "  inflating: test/male/1111.txt      \n",
            "  inflating: test/male/1112.txt      \n",
            "  inflating: test/male/1113.txt      \n",
            "  inflating: test/male/1114.txt      \n",
            "  inflating: test/male/1115.txt      \n",
            "  inflating: test/male/1116.txt      \n",
            "  inflating: test/male/1117.txt      \n",
            "  inflating: test/male/1118.txt      \n",
            "  inflating: test/male/1119.txt      \n",
            "  inflating: test/male/1120.txt      \n",
            "  inflating: test/male/1121.txt      \n",
            "  inflating: test/male/1122.txt      \n",
            "  inflating: test/male/1123.txt      \n",
            "  inflating: test/male/1124.txt      \n",
            "  inflating: test/male/1125.txt      \n",
            "  inflating: test/male/1126.txt      \n",
            "  inflating: test/male/1127.txt      \n",
            "  inflating: test/male/1128.txt      \n",
            "  inflating: test/male/1129.txt      \n",
            "  inflating: test/male/1130.txt      \n",
            "  inflating: test/male/1131.txt      \n",
            "  inflating: test/male/1132.txt      \n",
            "  inflating: test/male/1133.txt      \n",
            "  inflating: test/male/1134.txt      \n",
            "  inflating: test/male/1135.txt      \n",
            "  inflating: test/male/1136.txt      \n",
            "  inflating: test/male/1137.txt      \n",
            "  inflating: test/male/1138.txt      \n",
            "  inflating: test/male/1139.txt      \n",
            "  inflating: test/male/1140.txt      \n",
            "  inflating: test/male/1141.txt      \n",
            "  inflating: test/male/1142.txt      \n",
            "  inflating: test/male/1143.txt      \n",
            "  inflating: test/male/1144.txt      \n",
            "  inflating: test/male/1145.txt      \n",
            "  inflating: test/male/1146.txt      \n",
            "  inflating: test/male/1147.txt      \n",
            "  inflating: test/male/1148.txt      \n",
            "  inflating: test/male/1149.txt      \n",
            "  inflating: test/male/1150.txt      \n",
            "  inflating: test/male/1151.txt      \n",
            "  inflating: test/male/1152.txt      \n",
            "  inflating: test/male/1153.txt      \n",
            "  inflating: test/male/1154.txt      \n",
            "  inflating: test/male/1155.txt      \n",
            "  inflating: test/male/1156.txt      \n",
            "  inflating: test/male/1157.txt      \n",
            "  inflating: test/male/1158.txt      \n",
            "  inflating: test/male/1159.txt      \n",
            "  inflating: test/male/1160.txt      \n",
            "  inflating: test/male/1161.txt      \n",
            "  inflating: test/male/1162.txt      \n",
            "  inflating: test/male/1163.txt      \n",
            "  inflating: test/male/1164.txt      \n",
            "  inflating: test/male/1165.txt      \n",
            "  inflating: test/male/1166.txt      \n",
            "  inflating: test/male/1167.txt      \n",
            "  inflating: test/male/1168.txt      \n",
            "  inflating: test/male/1169.txt      \n",
            "  inflating: test/male/1170.txt      \n",
            "  inflating: test/male/1171.txt      \n",
            "  inflating: test/male/1172.txt      \n",
            "  inflating: test/male/1173.txt      \n",
            "  inflating: test/male/1174.txt      \n",
            "  inflating: test/male/1175.txt      \n",
            "  inflating: test/male/1176.txt      \n",
            "  inflating: test/male/1177.txt      \n",
            "  inflating: test/male/1178.txt      \n",
            "  inflating: test/male/1179.txt      \n",
            "  inflating: test/male/1180.txt      \n",
            "  inflating: test/male/1181.txt      \n",
            "  inflating: test/male/1182.txt      \n",
            "  inflating: test/male/1183.txt      \n",
            "  inflating: test/male/1184.txt      \n",
            "  inflating: test/male/1185.txt      \n",
            "  inflating: test/male/1186.txt      \n",
            "  inflating: test/male/1187.txt      \n",
            "  inflating: test/male/1188.txt      \n",
            "  inflating: test/male/1189.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "N9NS4kFWn27i",
        "outputId": "77d4ca4a-98c3-4d6f-be9f-17dbd41d12e0"
      },
      "source": [
        "test_data = []\n",
        "\n",
        "def read_test_files(path, tag):\n",
        "  for file in os.listdir(path):\n",
        "      with open(f\"{path}/{file}\", 'r', encoding='utf-8') as f:\n",
        "        test_data.append([f.read().strip(), tag])\n",
        "\n",
        "read_test_files(\"/content/test/female\", \"female\")\n",
        "read_test_files(\"/content/test/male\", \"male\")\n",
        "\n",
        "test_dataset = pd.DataFrame(test_data, columns = [\"Comment\", \"Gender\"]) \n",
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salam.hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>378 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Comment  Gender\n",
              "0    با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...  female\n",
              "1    سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...  female\n",
              "2    salam.hotel shayan kheili ali bood makhsoosan ...  female\n",
              "3    من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...  female\n",
              "4    هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...  female\n",
              "..                                                 ...     ...\n",
              "373  سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...    male\n",
              "374  من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...    male\n",
              "375  من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...    male\n",
              "376  ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...    male\n",
              "377  من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...    male\n",
              "\n",
              "[378 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "aaMNwfVOv18J",
        "outputId": "e15cf19b-525f-4c31-a733-142b0947016b"
      },
      "source": [
        "test_df = pd.DataFrame(list(test_dataset.apply(preprocess, axis=1)))\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Words</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...</td>\n",
              "      <td>سلا عرض ادب خسته بود#باش برا اولین هتل هلیارو ...</td>\n",
              "      <td>[با, سلام, عرض, ادب, و, خسته, نباشید, برای, او...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...</td>\n",
              "      <td>سلا سا خوب داشت#دار ممنون کل برا سفر ک از کرد#...</td>\n",
              "      <td>[سلام, سایت, خوبی, دارید, ., ممنون, ., من, کلی...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salam.hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>salam hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>[salam, ., hotel, kheili, ali, bood, ., be, kh...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...</td>\n",
              "      <td>دیروز ک برگ رفتن نظر دوس راجع هتل رو خوند متاس...</td>\n",
              "      <td>[من, دیروز, از, کیش, برگشتم, قبل, از, رفتن, نظ...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...</td>\n",
              "      <td>هتل خوبیه شوهر تو سو نفره بود#باش صبحانه  خوبه...</td>\n",
              "      <td>[هتل, خوبیه, من, و, شوهرم, تو, سوییت, 5, نفره,...</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...</td>\n",
              "      <td>سلا تاریخ اقام مد شب خانواده اتاق ابتدا ورود ت...</td>\n",
              "      <td>[سلام, تاریخ, اقامت, به, مدت, 3, شب, 2, خانواد...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...</td>\n",
              "      <td>باتفاق همسر دخ کوچک روز این هتل اقام داشت اتاق...</td>\n",
              "      <td>[من, باتفاق, همسر, و, دختر, کوچکم, 3, روز, در,...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...</td>\n",
              "      <td>تاریخ این هتل اقام دا گویا این هتل تازگ بازساز...</td>\n",
              "      <td>[من, از, تاریخ, تا, در, این, هتل, اقامت, داشتم...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...</td>\n",
              "      <td>ماتازه ک برگ سه روز این هتل اقام داشت بسیار هت...</td>\n",
              "      <td>[از, کیش, برگشتیم, سه, روز, در, این, هتل, اقام...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...</td>\n",
              "      <td>تاشهریور دراین هتل باخانواد بود#باش راست اصلا ...</td>\n",
              "      <td>[من, از, 22, تا, 25, شهریور, دراین, هتل, بودم,...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>378 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Comment  ...  Gender\n",
              "0    با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...  ...  female\n",
              "1    سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...  ...  female\n",
              "2    salam.hotel shayan kheili ali bood makhsoosan ...  ...  female\n",
              "3    من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...  ...  female\n",
              "4    هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...  ...  female\n",
              "..                                                 ...  ...     ...\n",
              "373  سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...  ...    male\n",
              "374  من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...  ...    male\n",
              "375  من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...  ...    male\n",
              "376  ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...  ...    male\n",
              "377  من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...  ...    male\n",
              "\n",
              "[378 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YRVYqxewqX7"
      },
      "source": [
        "Feature1 : number of character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwIpjo3owetg"
      },
      "source": [
        "test_df['F1'] = test_df.apply(lambda row: len(row.Comment), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-i50gztw22q"
      },
      "source": [
        "Feature 2: The number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWbkN9kaxOMs"
      },
      "source": [
        "test_df['F2'] = test_df.apply(lambda row: len(row.Text.split()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDUY297xOMz"
      },
      "source": [
        "Feature 3: Vocabulary richness\n",
        "\n",
        "unique words count / total words count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_nFHxtbxOM4"
      },
      "source": [
        "test_df['F3'] = test_df.apply(lambda row: len(set(row.Text.split())) / len(row.Text.split()), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPal_HsIxOM6"
      },
      "source": [
        "Feature 4 :  (hapax dislegomena) / N\n",
        "\n",
        "A hapax dislegomena is a word or an expression that occurs only twice within a context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Hp0WnPxOM8"
      },
      "source": [
        "test_df['F4'] = test_df.apply(lambda row: word_frequency(row.Text,2), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5zNa6txOM-"
      },
      "source": [
        "Feature5 : yule's k measure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKf43eeXxOM_"
      },
      "source": [
        "test_df['F5'] = test_df.apply(lambda row: yulesk(row.Text), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dy6zVSjxONB"
      },
      "source": [
        "Feature 6: The number of single-character words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDjDacCixONB"
      },
      "source": [
        "test_df['F6'] = test_df.apply(lambda row: k_char_cnt(row.Text, 1), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvTCmKPPxONC"
      },
      "source": [
        "Feature 7: Alphabet letters count\n",
        "\n",
        "alphabet letters count / total characters count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh1rhisxxOND"
      },
      "source": [
        "test_df['F7'] = test_df.apply(lambda row: sum(c.isalpha() for c in row.Comment) / len(row.Comment), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEjzRDVnxONE"
      },
      "source": [
        "Feature 8 : (hapax legomena) / N\n",
        "\n",
        "A hapax legomena is a word or an expression that occurs only once within a context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAsI_BgQxONE"
      },
      "source": [
        "test_df['F8'] = test_df.apply(lambda row: word_frequency(row.Text,1), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LemBll4xONF"
      },
      "source": [
        "Feature 9 :First person connected pronoun / other pronouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JihL_OwxONF"
      },
      "source": [
        "test_df['F9'] = test_df.apply(lambda row: pronoun_ratio(row.Comment), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2OAU5LuxONG"
      },
      "source": [
        "Feature 10: The number of lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlXcg-W5xONH"
      },
      "source": [
        "test_df['F10'] = test_df.apply(lambda row: row.Comment.count('\\n') + 1, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AgT_dZxuxONH",
        "outputId": "6cc4025a-f375-4f3b-d295-94af17e74ebc"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Words</th>\n",
              "      <th>Gender</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...</td>\n",
              "      <td>سلا عرض ادب خسته بود#باش برا اولین هتل هلیارو ...</td>\n",
              "      <td>[با, سلام, عرض, ادب, و, خسته, نباشید, برای, او...</td>\n",
              "      <td>female</td>\n",
              "      <td>139</td>\n",
              "      <td>22</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-433.884298</td>\n",
              "      <td>1</td>\n",
              "      <td>0.762590</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...</td>\n",
              "      <td>سلا سا خوب داشت#دار ممنون کل برا سفر ک از کرد#...</td>\n",
              "      <td>[سلام, سایت, خوبی, دارید, ., ممنون, ., من, کلی...</td>\n",
              "      <td>female</td>\n",
              "      <td>455</td>\n",
              "      <td>68</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.088235</td>\n",
              "      <td>-143.560452</td>\n",
              "      <td>5</td>\n",
              "      <td>0.762637</td>\n",
              "      <td>0.632353</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salam.hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>salam hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>[salam, ., hotel, kheili, ali, bood, ., be, kh...</td>\n",
              "      <td>female</td>\n",
              "      <td>273</td>\n",
              "      <td>38</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>-254.774749</td>\n",
              "      <td>0</td>\n",
              "      <td>0.860806</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...</td>\n",
              "      <td>دیروز ک برگ رفتن نظر دوس راجع هتل رو خوند متاس...</td>\n",
              "      <td>[من, دیروز, از, کیش, برگشتم, قبل, از, رفتن, نظ...</td>\n",
              "      <td>female</td>\n",
              "      <td>600</td>\n",
              "      <td>86</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>-114.266668</td>\n",
              "      <td>4</td>\n",
              "      <td>0.778333</td>\n",
              "      <td>0.732558</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...</td>\n",
              "      <td>هتل خوبیه شوهر تو سو نفره بود#باش صبحانه  خوبه...</td>\n",
              "      <td>[هتل, خوبیه, من, و, شوهرم, تو, سوییت, 5, نفره,...</td>\n",
              "      <td>female</td>\n",
              "      <td>288</td>\n",
              "      <td>36</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>-269.204390</td>\n",
              "      <td>0</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...</td>\n",
              "      <td>سلا تاریخ اقام مد شب خانواده اتاق ابتدا ورود ت...</td>\n",
              "      <td>[سلام, تاریخ, اقامت, به, مدت, 3, شب, 2, خانواد...</td>\n",
              "      <td>male</td>\n",
              "      <td>934</td>\n",
              "      <td>139</td>\n",
              "      <td>0.784173</td>\n",
              "      <td>0.079137</td>\n",
              "      <td>-71.097203</td>\n",
              "      <td>1</td>\n",
              "      <td>0.762313</td>\n",
              "      <td>0.647482</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...</td>\n",
              "      <td>باتفاق همسر دخ کوچک روز این هتل اقام داشت اتاق...</td>\n",
              "      <td>[من, باتفاق, همسر, و, دختر, کوچکم, 3, روز, در,...</td>\n",
              "      <td>male</td>\n",
              "      <td>470</td>\n",
              "      <td>66</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>-147.897710</td>\n",
              "      <td>1</td>\n",
              "      <td>0.772340</td>\n",
              "      <td>0.651515</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...</td>\n",
              "      <td>تاریخ این هتل اقام دا گویا این هتل تازگ بازساز...</td>\n",
              "      <td>[من, از, تاریخ, تا, در, این, هتل, اقامت, داشتم...</td>\n",
              "      <td>male</td>\n",
              "      <td>518</td>\n",
              "      <td>74</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.067568</td>\n",
              "      <td>-131.976388</td>\n",
              "      <td>1</td>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.689189</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...</td>\n",
              "      <td>ماتازه ک برگ سه روز این هتل اقام داشت بسیار هت...</td>\n",
              "      <td>[از, کیش, برگشتیم, سه, روز, در, این, هتل, اقام...</td>\n",
              "      <td>male</td>\n",
              "      <td>225</td>\n",
              "      <td>34</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>-282.922858</td>\n",
              "      <td>1</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...</td>\n",
              "      <td>تاشهریور دراین هتل باخانواد بود#باش راست اصلا ...</td>\n",
              "      <td>[من, از, 22, تا, 25, شهریور, دراین, هتل, بودم,...</td>\n",
              "      <td>male</td>\n",
              "      <td>763</td>\n",
              "      <td>100</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>-97.700000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.779817</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>378 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Comment  ... F10\n",
              "0    با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...  ...   3\n",
              "1    سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...  ...   1\n",
              "2    salam.hotel shayan kheili ali bood makhsoosan ...  ...   1\n",
              "3    من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...  ...   1\n",
              "4    هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...  ...   1\n",
              "..                                                 ...  ...  ..\n",
              "373  سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...  ...   3\n",
              "374  من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...  ...   1\n",
              "375  من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...  ...   1\n",
              "376  ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...  ...   1\n",
              "377  من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...  ...  12\n",
              "\n",
              "[378 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkomSr8ryd5Y"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-pw5Uhl3yd5e",
        "outputId": "4ce2cda7-4a3d-4039-a330-3349664c3513"
      },
      "source": [
        "normalized_test_df = pd.concat([test_df.iloc[:,:4], (test_df.iloc[:,4:] - test_df.iloc[:,4:].min()) / (test_df.iloc[:,4:].max() - test_df.iloc[:,4:].min())], axis=1)\n",
        "normalized_test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Words</th>\n",
              "      <th>Gender</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...</td>\n",
              "      <td>سلا عرض ادب خسته بود#باش برا اولین هتل هلیارو ...</td>\n",
              "      <td>[با, سلام, عرض, ادب, و, خسته, نباشید, برای, او...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.048901</td>\n",
              "      <td>0.058997</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.836180</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.457269</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.086957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...</td>\n",
              "      <td>سلا سا خوب داشت#دار ممنون کل برا سفر ک از کرد#...</td>\n",
              "      <td>[سلام, سایت, خوبی, دارید, ., ممنون, ., من, کلی...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.168688</td>\n",
              "      <td>0.194690</td>\n",
              "      <td>0.380252</td>\n",
              "      <td>0.441176</td>\n",
              "      <td>0.953677</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.457457</td>\n",
              "      <td>0.309541</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>salam.hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>salam hotel shayan kheili ali bood makhsoosan ...</td>\n",
              "      <td>[salam, ., hotel, kheili, ali, bood, ., be, kh...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.099697</td>\n",
              "      <td>0.106195</td>\n",
              "      <td>0.704261</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.908667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.845194</td>\n",
              "      <td>0.604621</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...</td>\n",
              "      <td>دیروز ک برگ رفتن نظر دوس راجع هتل رو خوند متاس...</td>\n",
              "      <td>[من, دیروز, از, کیش, برگشتم, قبل, از, رفتن, نظ...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.223654</td>\n",
              "      <td>0.247788</td>\n",
              "      <td>0.542636</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.965533</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.519451</td>\n",
              "      <td>0.497731</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...</td>\n",
              "      <td>هتل خوبیه شوهر تو سو نفره بود#باش صبحانه  خوبه...</td>\n",
              "      <td>[هتل, خوبیه, من, و, شوهرم, تو, سوییت, 5, نفره,...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.105383</td>\n",
              "      <td>0.100295</td>\n",
              "      <td>0.843915</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.902828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.530971</td>\n",
              "      <td>0.791328</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...</td>\n",
              "      <td>سلا تاریخ اقام مد شب خانواده اتاق ابتدا ورود ت...</td>\n",
              "      <td>[سلام, تاریخ, اقامت, به, مدت, 3, شب, 2, خانواد...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.350265</td>\n",
              "      <td>0.404130</td>\n",
              "      <td>0.393628</td>\n",
              "      <td>0.395683</td>\n",
              "      <td>0.983004</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.456174</td>\n",
              "      <td>0.337954</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.086957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...</td>\n",
              "      <td>باتفاق همسر دخ کوچک روز این هتل اقام داشت اتاق...</td>\n",
              "      <td>[من, باتفاق, همسر, و, دختر, کوچکم, 3, روز, در,...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.174375</td>\n",
              "      <td>0.188791</td>\n",
              "      <td>0.446609</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.951922</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.495781</td>\n",
              "      <td>0.345528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...</td>\n",
              "      <td>تاریخ این هتل اقام دا گویا این هتل تازگ بازساز...</td>\n",
              "      <td>[من, از, تاریخ, تا, در, این, هتل, اقامت, داشتم...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.192570</td>\n",
              "      <td>0.212389</td>\n",
              "      <td>0.430502</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.958365</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.487604</td>\n",
              "      <td>0.416282</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...</td>\n",
              "      <td>ماتازه ک برگ سه روز این هتل اقام داشت بسیار هت...</td>\n",
              "      <td>[از, کیش, برگشتیم, سه, روز, در, این, هتل, اقام...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.081501</td>\n",
              "      <td>0.094395</td>\n",
              "      <td>0.669468</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.897276</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.605028</td>\n",
              "      <td>0.613343</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...</td>\n",
              "      <td>تاشهریور دراین هتل باخانواد بود#باش راست اصلا ...</td>\n",
              "      <td>[من, از, 22, تا, 25, شهریور, دراین, هتل, بودم,...</td>\n",
              "      <td>male</td>\n",
              "      <td>0.285444</td>\n",
              "      <td>0.289086</td>\n",
              "      <td>0.072857</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.972237</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.525309</td>\n",
              "      <td>0.023415</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.478261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>378 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Comment  ...       F10\n",
              "0    با سلام\\nعرض ادب و خسته نباشید \\nبرای اولین با...  ...  0.086957\n",
              "1    سلام سایت خوبی دارید.ممنون.من کلی برای سفرم به...  ...  0.000000\n",
              "2    salam.hotel shayan kheili ali bood makhsoosan ...  ...  0.000000\n",
              "3    من دیروز از کیش برگشتم قبل از رفتن نظرات دوستا...  ...  0.000000\n",
              "4    هتل خوبیه من و شوهرم  تو سوییت 5 نفره بودیم صب...  ...  0.000000\n",
              "..                                                 ...  ...       ...\n",
              "373  سلام\\nتاریخ اقامت 1389/11/28 به مدت 3 شب 2 خان...  ...  0.086957\n",
              "374  من باتفاق همسر و دختر کوچکم 3 روز در این هتل ا...  ...  0.000000\n",
              "375  من از تاریخ 25/02تا 28/02در این هتل اقامت داشت...  ...  0.000000\n",
              "376  ماتازه از کیش برگشتیم سه روز در این هتل اقامت ...  ...  0.000000\n",
              "377  من از 22تا25شهریور دراین هتل باخانوادم بودم\\nر...  ...  0.478261\n",
              "\n",
              "[378 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaVc6kyY1Sde"
      },
      "source": [
        "test_df.to_csv (r'/content/test_dataframe.csv', index = False, header=True, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImOkAxj21yzQ"
      },
      "source": [
        "Word2Vec Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4byB6O2S1yzS",
        "outputId": "c7b7e1c1-e12d-4584-a681-7aaadd00ccf3"
      },
      "source": [
        "test_input_sentences  = [comment for comment in test_df.Words]\n",
        "\n",
        "X_test_dataset = np.array([model[txt].sum(axis=0) for txt in test_input_sentences])\n",
        "Y_test_dataset = np.array([0 if gnd=='female' else 1 for gnd in test_df['Gender']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZouqFZD38gd"
      },
      "source": [
        "Ensemble classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgTrk-7q38gf"
      },
      "source": [
        "def test_ensemble_classification(selected_clf):\n",
        "  all_pred = []\n",
        "  for clfp in [test_classifiers_profile[idx] for idx in selected_clf]:\n",
        "      (x_train, x_test, y_train, y_test, clf, name, vectorizer) = clfp\n",
        "        \n",
        "      if vectorizer:\n",
        "        x_train = vectorizer.fit_transform(x_train)\n",
        "        x_test = vectorizer.transform(x_test)\n",
        "        \n",
        "      clf.fit(x_train, y_train)\n",
        "        \n",
        "      pred = clf.predict(x_test)\n",
        "      all_pred.append(pred)\n",
        "      print(f\"{name+':':<70}{accuracy_score(y_test, pred):<20}\")\n",
        "\n",
        "  all_pred = np.vstack(all_pred)\n",
        "  y_pred = ['male' if list(all_pred[:,idx]).count('male') > list(all_pred[:,idx]).count('female') else 'female' for idx in range(all_pred.shape[1])]\n",
        "  print(f\"\\nEnsemble accuracy:{accuracy_score(y_test, y_pred):<70}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mbBlK2Ddwu-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y04iFPyJ2Hvc"
      },
      "source": [
        "test_classifiers_profile = [\n",
        "        #(X_b, Y_b, svm.SVC(kernel='rbf'), 'SVM with Bert on raw data (kernel: RBF)',None),\n",
        "        (X_dataset, X_test_dataset, Y_dataset, Y_test_dataset, LogisticRegression(solver='liblinear', max_iter=500), 'LogisticRegression with Word2Vec on raw data (solver=liblinear)',None),\n",
        "        (df.Comment, test_df.Comment, df.Gender, test_df.Gender, LogisticRegression(solver='liblinear', max_iter=500), 'LogisticRegression with TfidfVector on raw data', TfidfVectorizer()),\n",
        "        #(df.Comment, df.Gender, LogisticRegression(solver='liblinear', max_iter=500), 'LogisticRegression with CountVector on raw data', CountVectorizer()),\n",
        "        (df.Comment, test_df.Comment, df.Gender, test_df.Gender, MultinomialNB(), 'MultinomalNB with CountVector on raw data', CountVectorizer()),\n",
        "        #(df.Text, df.Gender, MultinomialNB(), 'MultinomalNB with CountVector on preprocessed data', CountVectorizer()),\n",
        "        #(pd.concat([df.iloc[:,4:8], df.iloc[:,9:]], axis=1).to_numpy(), df.Gender, MultinomialNB(), 'MultinomalNB with features',None),\n",
        "        #(normalized_df.iloc[:, 4:].to_numpy(), df.Gender, MultinomialNB(), 'MultinomalNB with normalized features',None),\n",
        "        #(X_dataset, Y_dataset, svm.SVC(kernel='rbf'), 'SVM with Word2Vec on raw data (kernel: RBF)',None),\n",
        "        # The following line has been turned into a comment because it needs an immense amount of time to execute.\n",
        "        #(X_dataset, Y_dataset, svm.SVC(kernel='linear'), 'SVM with Word2Vec on raw data (kernel: Linear)',None),\n",
        "        #(X_dataset, Y_dataset, svm.SVC(kernel=PUK_kernel), 'SVM with Word2Vec on raw data (kernel: Pearson VII)',None),\n",
        "        (df.Comment, test_df.Comment, df.Gender, test_df.Gender, svm.SVC(kernel='rbf'), 'SVM with TfidfVector on raw data (kernel: RBF)', TfidfVectorizer()),\n",
        "        (df.Comment, test_df.Comment, df.Gender, test_df.Gender, svm.SVC(kernel='linear'), 'SVM with TfidfVector on raw data (kernel: Linear)', TfidfVectorizer())#,\n",
        "        #(df.Comment, df.Gender, svm.SVC(kernel=modified_PUK_kernel), 'SVM with TfidfVector on raw data (kernel: Pearson VII)', TfidfVectorizer()),\n",
        "        #(df.Text, df.Gender, svm.SVC(kernel='rbf'), 'SVM with TfidfVector on preprocessed data (kernel: RBF)', TfidfVectorizer()),\n",
        "        #(df.Text, df.Gender, svm.SVC(kernel='linear'), 'SVM with TfidfVector on preprocessed data (kernel: Linear)', TfidfVectorizer()),\n",
        "        #(df.Text, df.Gender, svm.SVC(kernel=modified_PUK_kernel), 'SVM with TfidfVector on preprocessed data (kernel: Pearson VII)', TfidfVectorizer()),\n",
        "        #(df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='rbf'), 'SVM with features (kernel: RBF)',None),\n",
        "        #(df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='linear'), 'SVM with features (kernel: Linear)'),\n",
        "        #(df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel=PUK_kernel), 'SVM with features (kernel: Pearson VII)'),\n",
        "        #(normalized_df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='rbf'), 'SVM with normalized features (kernel: RBF)',None),\n",
        "        #(normalized_df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel='linear'), 'SVM with normalized features (kernel: Linear)'),\n",
        "        #(normalized_df.iloc[:, 4:].to_numpy(), df.Gender, svm.SVC(kernel=PUK_kernel), 'SVM with normalized features (kernel: Pearson VII)'),\n",
        "        #(X_dataset, Y_dataset, tree.DecisionTreeClassifier(), 'Decision Tree with Word2Vec on raw data',None),\n",
        "        #(df.Comment, df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with CountVector on raw data', CountVectorizer()),\n",
        "        #(df.Comment, df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with CountVector on preprocessed data', CountVectorizer()),\n",
        "        #(df.iloc[:, 4:].to_numpy(), df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with features',None),\n",
        "        #(normalized_df.iloc[:, 4:].to_numpy(), df.Gender, tree.DecisionTreeClassifier(), 'Decision Tree with normalized features',None),\n",
        "        #(X_dataset, Y_dataset, AdaBoostClassifier(n_estimators=100, random_state=0), 'AdaBoostClassifier with Word2Vec on raw data',None),\n",
        "        #(df.Comment, df.Gender, AdaBoostClassifier(n_estimators=100, random_state=0), 'AdaBoostClassifier with TfidfVector on raw data', TfidfVectorizer())\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdqKpQg63hIq"
      },
      "source": [
        "Ensemble classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkyHgnf33hIv",
        "outputId": "e5ba3778-557c-43fe-ab5b-b8da7dad69b0"
      },
      "source": [
        "classifiers = [0, 1, 2, 3, 4]\n",
        "test_ensemble_classification(classifiers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression with Word2Vec on raw data (solver=liblinear):      0.5529100529100529  \n",
            "LogisticRegression with TfidfVector on raw data:                      0.5634920634920635  \n",
            "MultinomalNB with CountVector on raw data:                            0.6084656084656085  \n",
            "SVM with TfidfVector on raw data (kernel: RBF):                       0.5687830687830688  \n",
            "SVM with TfidfVector on raw data (kernel: Linear):                    0.5767195767195767  \n",
            "\n",
            "Ensemble accuracy:0.582010582010582                                                     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}